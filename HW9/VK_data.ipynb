{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, LabelEncoder, MinMaxScaler,  Imputer\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# import cPickle as pickle\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 8)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34011 entries, 0 to 34010\n",
      "Data columns (total 22 columns):\n",
      "bdate         27938 non-null object\n",
      "langs         4425 non-null object\n",
      "political     5193 non-null float64\n",
      "smoking       5987 non-null float64\n",
      "verified      34011 non-null int64\n",
      "life_main     5965 non-null float64\n",
      "alcohol       5915 non-null float64\n",
      "tv            3272 non-null object\n",
      "country       32669 non-null object\n",
      "sex           34011 non-null int64\n",
      "last_name     34011 non-null object\n",
      "age           34011 non-null float64\n",
      "id            34011 non-null int64\n",
      "posts         34011 non-null object\n",
      "interests     5383 non-null object\n",
      "university    14180 non-null float64\n",
      "first_name    34011 non-null object\n",
      "city          31156 non-null object\n",
      "religion      6096 non-null object\n",
      "movies        4427 non-null object\n",
      "relation      14180 non-null float64\n",
      "music         4709 non-null object\n",
      "dtypes: float64(7), int64(3), object(12)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/vk_users_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['interests'] = df['interests'].fillna(\"empty\")\n",
    "df['movies'] = df['movies'].fillna(\"empty\")\n",
    "df['music'] = df['music'].fillna(\"empty\")\n",
    "df['tv'] = df['tv'].fillna(\"empty\")\n",
    "# –∑–∞–º–µ–Ω–∏–º –Ω–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ -1\n",
    "df = df.fillna(-1)\n",
    "# –í —Å—Ç–æ–ª–±—Ü–µ university —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è id —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –ø–æ –ë–î VK. \n",
    "# –ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –µ—Å–ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω, —Ç–æ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å—Ç—å –≤—ã—Å—à–µ–µ \n",
    "# –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –∏–Ω–∞—á–µ –Ω–µ—Ç (—Ö–æ—Ç—è —Å—Ç—Ä–æ–≥–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫, –æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—Å—Ç–æ \n",
    "# –Ω–µ —É–∫–∞–∑–∞–Ω. –ù–æ –ø—Ä–∏–º–µ–º —Ç–∞–∫–æ–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ)\n",
    "df['high_education'] = df['university'].apply(lambda x: 0 if x < -0.5 else 1)\n",
    "df['age'] = df['age'].astype(int)\n",
    "df['political'] = df['political'].astype(int)\n",
    "df['smoking'] = df['smoking'].astype(int)\n",
    "df['alcohol'] = df['alcohol'].astype(int)\n",
    "df['relation'] = df['relation'].astype(int)\n",
    "df['life_main'] = df['life_main'].astype(int)\n",
    "# df['posts'] = df['posts'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bdate</th>\n",
       "      <th>langs</th>\n",
       "      <th>political</th>\n",
       "      <th>smoking</th>\n",
       "      <th>verified</th>\n",
       "      <th>life_main</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>tv</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>interests</th>\n",
       "      <th>university</th>\n",
       "      <th>first_name</th>\n",
       "      <th>city</th>\n",
       "      <th>religion</th>\n",
       "      <th>movies</th>\n",
       "      <th>relation</th>\n",
       "      <th>music</th>\n",
       "      <th>high_education</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>–í–∏—Ç–∞–ª—è</td>\n",
       "      <td>–ú–æ—Å–∫–≤–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>üîû–ù–µ –ª–∞–π–∫–∞—é, –≤–∏–¥–µ–æ –Ω–µ —Å–º–æ—Ç—Ä—é, –≤ –≥—Ä—É–ø–ø—ã –Ω–µ –≤—Å—Ç—É–ø...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>–û–ª–µ–≥</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.00</td>\n",
       "      <td>–ê—Ä—Ç—É—Ä</td>\n",
       "      <td>–ù–∞–±–µ—Ä–µ–∂–Ω—ã–µ –ß–µ–ª–Ω—ã</td>\n",
       "      <td>4ayan.ru</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Zara, Pull and Bear, Massimo Dutti, Bershka, S...</td>\n",
       "      <td>–£–∫—Ä–∞–∏–Ω–∞</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Zara, Pull and Bear, Massimo Dutti, Bershka, S...</td>\n",
       "      <td>1892.00</td>\n",
       "      <td>Zara</td>\n",
       "      <td>–î–Ω–µ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å–∫ (–î–Ω–µ–ø—Ä)</td>\n",
       "      <td>Buisness</td>\n",
       "      <td>Zara, Pull and Bear, Massimo Dutti, Bershka, S...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zara, Pull and Bear, Massimo Dutti, Bershka, S...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6.1989</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–£–∫—Ä–∞–∏–Ω–∞</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>–ù–∞—Ç–∞–ª—è</td>\n",
       "      <td>–õ—å–≤–æ–≤</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bdate langs  political  smoking  verified  life_main  alcohol  \\\n",
       "0      28.4    -1         -1       -1         0         -1       -1   \n",
       "1        -1    -1         -1       -1         0         -1       -1   \n",
       "2        -1    -1         -1       -1         1         -1       -1   \n",
       "3       1.1    -1          8       -1         0         -1       -1   \n",
       "4  6.6.1989    -1         -1       -1         0         -1       -1   \n",
       "\n",
       "                                                  tv  country  sex  \\\n",
       "0                                              empty   –†–æ—Å—Å–∏—è    2   \n",
       "1                                              empty   –†–æ—Å—Å–∏—è    2   \n",
       "2                                              empty   –†–æ—Å—Å–∏—è    2   \n",
       "3  Zara, Pull and Bear, Massimo Dutti, Bershka, S...  –£–∫—Ä–∞–∏–Ω–∞    2   \n",
       "4                                              empty  –£–∫—Ä–∞–∏–Ω–∞    1   \n",
       "\n",
       "      ...                                               interests  university  \\\n",
       "0     ...                                                   empty       -1.00   \n",
       "1     ...       üîû–ù–µ –ª–∞–π–∫–∞—é, –≤–∏–¥–µ–æ –Ω–µ —Å–º–æ—Ç—Ä—é, –≤ –≥—Ä—É–ø–ø—ã –Ω–µ –≤—Å—Ç—É–ø...        0.00   \n",
       "2     ...                                                   empty        0.00   \n",
       "3     ...       Zara, Pull and Bear, Massimo Dutti, Bershka, S...     1892.00   \n",
       "4     ...                                                   empty       -1.00   \n",
       "\n",
       "   first_name                    city  religion  \\\n",
       "0      –í–∏—Ç–∞–ª—è                  –ú–æ—Å–∫–≤–∞        -1   \n",
       "1        –û–ª–µ–≥                      -1        -1   \n",
       "2       –ê—Ä—Ç—É—Ä        –ù–∞–±–µ—Ä–µ–∂–Ω—ã–µ –ß–µ–ª–Ω—ã  4ayan.ru   \n",
       "3        Zara  –î–Ω–µ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å–∫ (–î–Ω–µ–ø—Ä)  Buisness   \n",
       "4      –ù–∞—Ç–∞–ª—è                   –õ—å–≤–æ–≤        -1   \n",
       "\n",
       "                                              movies relation  \\\n",
       "0                                              empty       -1   \n",
       "1                                              empty        0   \n",
       "2                                              empty        0   \n",
       "3  Zara, Pull and Bear, Massimo Dutti, Bershka, S...        0   \n",
       "4                                              empty       -1   \n",
       "\n",
       "                                               music high_education  \\\n",
       "0                                              empty              0   \n",
       "1                            ‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù‚òù              1   \n",
       "2                                              empty              1   \n",
       "3  Zara, Pull and Bear, Massimo Dutti, Bershka, S...              1   \n",
       "4                                              empty              0   \n",
       "\n",
       "  age_category  \n",
       "0            4  \n",
       "1            2  \n",
       "2            2  \n",
       "3            2  \n",
       "4            1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ß—Ç–æ–±—ã –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –Ω–∞—à—É –∑–∞–¥–∞—á—É –≤ –∑–∞–¥–∞—á—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —É–º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤–æ–∑—Ä–∞—Å—Ç–∞\n",
    "# —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –≤–æ–∑—Ä–∞—Å—Ç–∞ –æ—Ç 0 –¥–æ 18; –æ—Ç 18 –¥–æ 30; –æ—Ç 30 –¥–æ 50; –æ—Ç 50 –¥–æ 70 –∏ –æ—Ç 70 –¥–æ 110 - 5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n",
    "def age_cat(age):\n",
    "    if 0 <= age <= 18:\n",
    "        return 0\n",
    "    elif 18 < age <= 30:\n",
    "        return 1\n",
    "    elif 30 < age <= 50:\n",
    "        return 2\n",
    "    elif 50 < age <= 70:\n",
    "        return 3\n",
    "    elif 70 < age <= 110:\n",
    "        return 4\n",
    "    \n",
    "df['age_category'] = df['age'].apply(lambda x: age_cat(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bdate</th>\n",
       "      <th>langs</th>\n",
       "      <th>political</th>\n",
       "      <th>smoking</th>\n",
       "      <th>verified</th>\n",
       "      <th>life_main</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>tv</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>interests</th>\n",
       "      <th>university</th>\n",
       "      <th>first_name</th>\n",
       "      <th>city</th>\n",
       "      <th>religion</th>\n",
       "      <th>movies</th>\n",
       "      <th>relation</th>\n",
       "      <th>music</th>\n",
       "      <th>high_education</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11153</th>\n",
       "      <td>25.3.1936</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>–ú–∏—Ö–∞–∏–ª</td>\n",
       "      <td>–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>12.8</td>\n",
       "      <td>['–†—É—Å—Å–∫–∏–π', 'English']</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.00</td>\n",
       "      <td>–í–∞–ª–µ—Ä–∞</td>\n",
       "      <td>–°–∞–º–∞—Ä–∞</td>\n",
       "      <td>–ü–∞—Å—Ç–∞—Ñ–∞—Ä–∏–∞–Ω—Å—Ç–≤–æ</td>\n",
       "      <td>empty</td>\n",
       "      <td>2</td>\n",
       "      <td>empty</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27363</th>\n",
       "      <td>1.9.2001</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.00</td>\n",
       "      <td>–ù–∏–∫–∏—Ç–∞</td>\n",
       "      <td>–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>6</td>\n",
       "      <td>empty</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244</th>\n",
       "      <td>29.8.1991</td>\n",
       "      <td>['–†—É—Å—Å–∫–∏–π', '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞']</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>–®–æ—É –û–ø—Ä—ã</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>–ö–ª—É–±—ã, –ø–∞—Ä–Ω–∏, —Ç–∞–Ω—Ü—ã</td>\n",
       "      <td>327.00</td>\n",
       "      <td>–ú–∞—Ä–∏–Ω–∞</td>\n",
       "      <td>–ú–æ—Å–∫–≤–∞</td>\n",
       "      <td>–ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ</td>\n",
       "      <td>–£–Ω–∏–≤–µ—Ä, –ò–Ω—Ç–µ—Ä–Ω—ã, –û–¥–∏–Ω –¥–æ–º–∞, –ö—Ä–∏–∫, –ó–≤–æ–Ω–æ–∫</td>\n",
       "      <td>5</td>\n",
       "      <td>–¢–∞, –ø–æ–¥ –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –ø–æ–¥–≤–∏–≥–∞—Ç—å—Å—è</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29708</th>\n",
       "      <td>29.11.1945</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>–ì—Ä–∏—à–∞</td>\n",
       "      <td>–†–∞–¥—É–∂–Ω—ã–π</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            bdate                      langs  political  smoking  verified  \\\n",
       "11153   25.3.1936                         -1         -1       -1         0   \n",
       "6352         12.8     ['–†—É—Å—Å–∫–∏–π', 'English']         -1        2         0   \n",
       "27363    1.9.2001                         -1         -1       -1         0   \n",
       "19244   29.8.1991  ['–†—É—Å—Å–∫–∏–π', '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞']          3        4         0   \n",
       "29708  29.11.1945                         -1         -1       -1         0   \n",
       "\n",
       "       life_main  alcohol        tv country  sex     ...       \\\n",
       "11153         -1       -1     empty  –†–æ—Å—Å–∏—è    2     ...        \n",
       "6352          -1        1     empty  –†–æ—Å—Å–∏—è    2     ...        \n",
       "27363         -1       -1     empty  –†–æ—Å—Å–∏—è    2     ...        \n",
       "19244          2        5  –®–æ—É –û–ø—Ä—ã  –†–æ—Å—Å–∏—è    1     ...        \n",
       "29708         -1       -1     empty  –†–æ—Å—Å–∏—è    2     ...        \n",
       "\n",
       "                 interests  university  first_name             city  \\\n",
       "11153                empty       -1.00      –ú–∏—Ö–∞–∏–ª  –ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥   \n",
       "6352                 empty        0.00      –í–∞–ª–µ—Ä–∞           –°–∞–º–∞—Ä–∞   \n",
       "27363                empty        0.00      –ù–∏–∫–∏—Ç–∞        –ö—Ä–∞—Å–Ω–æ–¥–∞—Ä   \n",
       "19244  –ö–ª—É–±—ã, –ø–∞—Ä–Ω–∏, —Ç–∞–Ω—Ü—ã      327.00      –ú–∞—Ä–∏–Ω–∞           –ú–æ—Å–∫–≤–∞   \n",
       "29708                empty       -1.00       –ì—Ä–∏—à–∞         –†–∞–¥—É–∂–Ω—ã–π   \n",
       "\n",
       "              religion                                    movies relation  \\\n",
       "11153               -1                                     empty       -1   \n",
       "6352   –ü–∞—Å—Ç–∞—Ñ–∞—Ä–∏–∞–Ω—Å—Ç–≤–æ                                     empty        2   \n",
       "27363               -1                                     empty        6   \n",
       "19244      –ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ  –£–Ω–∏–≤–µ—Ä, –ò–Ω—Ç–µ—Ä–Ω—ã, –û–¥–∏–Ω –¥–æ–º–∞, –ö—Ä–∏–∫, –ó–≤–æ–Ω–æ–∫        5   \n",
       "29708               -1                                     empty       -1   \n",
       "\n",
       "                                   music high_education age_category  \n",
       "11153                              empty              0            4  \n",
       "6352                               empty              1            0  \n",
       "27363                              empty              1            0  \n",
       "19244  –¢–∞, –ø–æ–¥ –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –ø–æ–¥–≤–∏–≥–∞—Ç—å—Å—è              1            1  \n",
       "29708                              empty              0            4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bdate</th>\n",
       "      <th>langs</th>\n",
       "      <th>political</th>\n",
       "      <th>smoking</th>\n",
       "      <th>verified</th>\n",
       "      <th>life_main</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>tv</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>interests</th>\n",
       "      <th>university</th>\n",
       "      <th>first_name</th>\n",
       "      <th>city</th>\n",
       "      <th>religion</th>\n",
       "      <th>movies</th>\n",
       "      <th>relation</th>\n",
       "      <th>music</th>\n",
       "      <th>high_education</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>27.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.00</td>\n",
       "      <td>–ê–Ω–∞—Å—Ç–∞—Å–∏—è</td>\n",
       "      <td>–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä</td>\n",
       "      <td>–ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ</td>\n",
       "      <td>empty</td>\n",
       "      <td>4</td>\n",
       "      <td>empty</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23533</th>\n",
       "      <td>19.3</td>\n",
       "      <td>['–†—É—Å—Å–∫–∏–π', 'Gagauz dili', 'T√ºrk√ße', '–£–∫—Ä–∞—ó–Ω—Å—å...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>–Ω–µ –Ω–∞ –≤–∏–∂—É</td>\n",
       "      <td>–£–∫—Ä–∞–∏–Ω–∞</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>–∫—É—à–∞—Ç—å, —Å–ø–∞—Ç—å, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Dima</td>\n",
       "      <td>–û–¥–µ—Å—Å–∞</td>\n",
       "      <td>–ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ</td>\n",
       "      <td>—Ä–∞–∑–Ω—ã–µ</td>\n",
       "      <td>4</td>\n",
       "      <td>—Ä–∞–∑–Ω—ã–µ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.00</td>\n",
       "      <td>–°–∞—à–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>20.6</td>\n",
       "      <td>['English']</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>empty</td>\n",
       "      <td>–ë–µ–ª–∞—Ä—É—Å—å</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.00</td>\n",
       "      <td>–ê–ª–µ–∫—Å–µ–π</td>\n",
       "      <td>–°–ª—É—Ü–∫</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>SUICIDEBOY, BONES, LIL PEEP, IMAGINE DRAGONS, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037</th>\n",
       "      <td>31.3.1905</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>–î–µ–Ω–∏—Å</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>-1</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bdate                                              langs  \\\n",
       "11313       27.8                                                 -1   \n",
       "23533       19.3  ['–†—É—Å—Å–∫–∏–π', 'Gagauz dili', 'T√ºrk√ße', '–£–∫—Ä–∞—ó–Ω—Å—å...   \n",
       "3386          -1                                                 -1   \n",
       "12659       20.6                                        ['English']   \n",
       "8037   31.3.1905                                                 -1   \n",
       "\n",
       "       political  smoking  verified  life_main  alcohol          tv   country  \\\n",
       "11313          3        1         0          1        1       empty    –†–æ—Å—Å–∏—è   \n",
       "23533          3        2         0          1        2  –Ω–µ –Ω–∞ –≤–∏–∂—É   –£–∫—Ä–∞–∏–Ω–∞   \n",
       "3386          -1        4         0          3        4       empty    –†–æ—Å—Å–∏—è   \n",
       "12659         -1        2         0         -1        2       empty  –ë–µ–ª–∞—Ä—É—Å—å   \n",
       "8037          -1       -1         0         -1       -1       empty    –†–æ—Å—Å–∏—è   \n",
       "\n",
       "       sex     ...                      interests  university  first_name  \\\n",
       "11313    1     ...                          empty        0.00   –ê–Ω–∞—Å—Ç–∞—Å–∏—è   \n",
       "23533    2     ...       –∫—É—à–∞—Ç—å, —Å–ø–∞—Ç—å, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç)        0.00        Dima   \n",
       "3386     2     ...                          empty        0.00        –°–∞—à–∞   \n",
       "12659    2     ...                          empty        0.00     –ê–ª–µ–∫—Å–µ–π   \n",
       "8037     2     ...                          empty       -1.00       –î–µ–Ω–∏—Å   \n",
       "\n",
       "            city     religion  movies relation  \\\n",
       "11313  –ö—Ä–∞—Å–Ω–æ–¥–∞—Ä  –ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ   empty        4   \n",
       "23533     –û–¥–µ—Å—Å–∞  –ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ  —Ä–∞–∑–Ω—ã–µ        4   \n",
       "3386          -1           -1   empty        0   \n",
       "12659      –°–ª—É—Ü–∫           -1   empty        0   \n",
       "8037          -1           -1   empty       -1   \n",
       "\n",
       "                                                   music high_education  \\\n",
       "11313                                              empty              1   \n",
       "23533                                             —Ä–∞–∑–Ω—ã–µ              1   \n",
       "3386                                               empty              1   \n",
       "12659  SUICIDEBOY, BONES, LIL PEEP, IMAGINE DRAGONS, ...              1   \n",
       "8037                                               empty              0   \n",
       "\n",
       "      age_category  \n",
       "11313            4  \n",
       "23533            1  \n",
       "3386             4  \n",
       "12659            4  \n",
       "8037             4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–∏–º –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "df_train.to_csv('learning/df_train.csv', sep='\\t', encoding='utf-8')\n",
    "df_test.to_csv('learning/df_test.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–º—ã—Å–ª –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö sex, political, smoking, alcohol, relation, life_main —Å–ª–µ–¥—É—é—â–∏–π (–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è API VK):\n",
    "\n",
    "1) sex - –ø–æ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n",
    "1 - –∂–µ–Ω—Å–∫–∏–π;\n",
    "2 - –º—É–∂—Å–∫–æ–π;\n",
    "0 - –ø–æ–ª –Ω–µ —É–∫–∞–∑–∞–Ω\n",
    "\n",
    "2) political - –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è:\n",
    "\n",
    "1 - –∫–æ–º–º—É–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ;\n",
    "2 - —Å–æ—Ü–∏–∞–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ;\n",
    "3 - —É–º–µ—Ä–µ–Ω–Ω—ã–µ;\n",
    "4 - –ª–∏–±–µ—Ä–∞–ª—å–Ω—ã–µ;\n",
    "5 - –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ;\n",
    "6 - –º–æ–Ω–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ;\n",
    "7 - —É–ª—å—Ç—Ä–∞–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ;\n",
    "8 - –∏–Ω–¥–∏—Ñ—Ñ–∏—Ä–µ–Ω—Ç–Ω—ã–µ;\n",
    "9 - –ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω—Å–∫–∏–µ;\n",
    "\n",
    "3) smoking, alcohol - –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∫—É—Ä–µ–Ω–∏—é, –∞–ª–∫–æ–≥–æ–ª—é:\n",
    "\n",
    "1 - —Ä–µ–∑–∫–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ;\n",
    "2 - –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ;\n",
    "3 - –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–Ω–æ–µ;\n",
    "4 - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ;\n",
    "5 - –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ;\n",
    "\n",
    "4) relation - —Å–µ–º–µ–π–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ:\n",
    "\n",
    "1 - –Ω–µ –∂–µ–Ω–∞—Ç/–Ω–µ –∑–∞–º—É–∂–µ–º;\n",
    "2 - –µ—Å—Ç—å –¥—Ä—É–≥/–µ—Å—Ç—å –ø–æ–¥—Ä—É–≥–∞;\n",
    "3 - –ø–æ–º–æ–ª–≤–ª–µ–Ω/–ø–æ–º–æ–ª–≤–ª–µ–Ω–∞;\n",
    "4 - –∂–µ–Ω–∞—Ç/–∑–∞–º—É–∂–µ–º;\n",
    "5 - –≤—Å—ë —Å–ª–æ–∂–Ω–æ;\n",
    "6 - –≤ –∞–∫—Ç–∏–≤–Ω–æ–º –ø–æ–∏—Å–∫–µ;\n",
    "7 - –≤–ª—é–±–ª—ë–Ω/–≤–ª—é–±–ª–µ–Ω–∞;\n",
    "8 - –≤ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –±—Ä–∞–∫–µ;\n",
    "0 - –Ω–µ —É–∫–∞–∑–∞–Ω–æ;\n",
    "\n",
    "5) life_main - –≥–ª–∞–≤–Ω–æ–µ –≤ –∂–∏–∑–Ω–∏:\n",
    "\n",
    "1 - —Å–µ–º—å—è –∏ –¥–µ—Ç–∏;\n",
    "2 - –∫–∞—Ä—å–µ—Ä–∞ –∏ –¥–µ–Ω—å–≥–∏;\n",
    "3 - —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è –∏ –æ—Ç–¥—ã—Ö;\n",
    "4 - –Ω–∞—É–∫–∞ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è;\n",
    "5 - —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–∏—Ä–∞;\n",
    "6 - —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ;\n",
    "7 - –∫—Ä–∞—Å–æ—Ç–∞ –∏ –∏—Å–∫—É—Å—Å—Ç–≤–æ;\n",
    "8 - —Å–ª–∞–≤–∞ –∏ –≤–ª–∏—è–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–æ–∑—Ä–∞—Å—Ç (–ø–æ –¥–∞–Ω–Ω—ã–º VK (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å —Å –æ—à–∏–±–∫–∞–º–∏: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –∫–∞–∫ –æ–Ω —Ç–∞–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è)) –ø–æ –ø–æ—Å—Ç–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ–≥–æ –ø–æ–ª—É (–ø–æ–ª —É–∫–∞–∑–∞–Ω –≤—Å–µ–≥–¥–∞) –∏ —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ personal, –∞ —Ç–∞–∫–∂–µ –ø–æ –Ω–∞–ª–∏—á–∏—é –≤—ã—Å—à–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –§—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_en = stopwords.words('english')\n",
    "stopwords_ru = stopwords.words('russian')\n",
    "stopwords_ge = stopwords.words('german')\n",
    "\n",
    "stopwords_all = stopwords_en + stopwords_ru + stopwords_ge\n",
    "\n",
    "# –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±—É–∫–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º —É–¥–∞–ª—è—Ç—å –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "additional_stopwords = \\\n",
    "[u'https', u'vk', u'com', u'id', u'ph', u'–¥—Ä', u'—Å–≤', u'ff', u'la', u'—ç—Ç–æ', \\\n",
    " u'de', u'pa', u'bb', u'p', u'—É–ª', u'–∏–Ω', u'http', u'ru', u'md', u'x', \\\n",
    " u'ft', u'—Å–±', u'b', u'–∫', u'www', u'youtube', u'–∫–∞', u'v', u'g', u'goo', u'gl', \\\n",
    " u'eu', u'u', u'te', u'un', u'–≤–∫', u'w', u'ly', u'su', u'bu', u'vl', u'—ç—Ç', u'r', u'e', \\\n",
    " u'—Å–≤–æ–π', u'–µ—â—ë', u'–º–æ–π', u'–≤–µ—Å—å', u'–¥–Ω—ë–º', u'youtu', u'—Ç–≤–æ–π', u'–Ω–∞—à', u'–≤–∞—à', u'—Ç–æ—Ç', u'—ç—Ç–æ—Ç']\n",
    "\n",
    "stopwords_all = stopwords_all + additional_stopwords\n",
    "\n",
    "# –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–¥–∞–ª—è–µ–º—ã–µ –ø–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–≤–∞\n",
    "delete_words = [u'—Å–≤–æ–π', u'–µ—â—ë', u'–º–æ–π', u'–≤–µ—Å—å', u'–¥–Ω—ë–º', u'youtu', u'—Ç–≤–æ–π', u'–Ω–∞—à', u'–≤–∞—à', u'—Ç–æ—Ç', u'—ç—Ç–æ—Ç']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫—É pymorphy2, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    return morph.parse(text)[0].normal_form\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    # –æ—á–∏—Å—Ç–∫–∞ –æ—Ç html-—Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # –≤—ã–¥–µ–ª–µ–Ω–∏–µ —Å–º–∞–π–ª–æ–≤\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—Å–ª–æ–≤–∞—Ä–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    text = re.sub(r'[\\W]+', ' ', text, flags=re.U) + ' '.join(emoticons).replace('-', '')\n",
    "    # —É–¥–∞–ª–∏–º —Ç–∞–∫–∂–µ –≤—Å–µ —Ü–∏—Ñ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—Ä—è–¥ –ª–∏ –ø–æ–ª–µ–∑–Ω—ã –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞\n",
    "    text = re.sub(r'\\d+', '', text, flags=re.U)\n",
    "    # —É–¥–∞–ª–∏–º –¥–≤–∞ –∏–ª–∏ –±–æ–ª–µ–µ –ø—Ä–æ–±–µ–ª–æ–≤\n",
    "    text = re.sub(r'[ ]{2,}', '', text, flags=re.U)\n",
    "    # —É–¥–∞–ª–∏–º –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è\n",
    "    text = re.sub(r'[_]+', '', text, flags=re.U)\n",
    "    # —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–±–µ–ª–∞–º –∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "    tokenized = [w for w in text.split() if w not in stopwords_all]\n",
    "    tokenized = [re.sub(r\"\\W\", \"\", w, flags=re.U) for w in tokenized]\n",
    "    # –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "    tokenized = [lemmatization(w) for w in tokenized]\n",
    "    # —É–¥–∞–ª–∏–º –≤—Å–µ —Å–ª–æ–≤–∞ –∏–∑ –æ–¥–Ω–æ–π –∏ –¥–≤—É—Ö –±—É–∫–≤. –í—Ä—è–¥ –ª–∏ –æ–Ω–∏ –Ω–µ—Å—É—Ç –±–æ–ª—å—à–æ–π —Å–º—ã—Å–ª. \n",
    "    # –¢–∞–∫–∂–µ —É–¥–∞–ª–∏–º \"—Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã\"\n",
    "    tokenized = [w for w in tokenized if len(w) > 2 and w not in delete_words]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_col(df):\n",
    "    return df['posts']\n",
    "\n",
    "def get_sex_col(df):\n",
    "    return df[['sex']]\n",
    "\n",
    "def get_interests_col(df):\n",
    "    return df[df['interests'] != \"\"]['interests']\n",
    "\n",
    "def get_movies_col(df):\n",
    "    return df[df['movies'] != \"\"]['movies']\n",
    "\n",
    "def get_music_col(df):\n",
    "    return df[df['music'] != \"\"]['music']\n",
    "\n",
    "def get_tv_col(df):\n",
    "    return df[df['tv'] != \"\"]['tv']\n",
    "\n",
    "def get_categorial_cols(df):\n",
    "    return df[['high_education', 'political', 'smoking', 'alcohol', 'relation', 'life_main']]\n",
    "\n",
    "def get_text_sample(df):   \n",
    "    return df[['posts','interests', 'movies', 'music', 'tv']]\n",
    "\n",
    "vec = make_union(*[\n",
    "    make_pipeline(FunctionTransformer(get_categorial_cols, validate=False), MinMaxScaler()),\n",
    "    make_pipeline(FunctionTransformer(get_posts_col, validate=False)), CountVectorizer(tokenizer=my_tokenizer)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° pipeline'–æ–º —á—Ç–æ-—Ç–æ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–æ–ª–±–µ—Ü —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208,)\n",
      "(6803,)\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['age_category']\n",
    "y_test = df_test['age_category']\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('learning/y_train', sep='\\t')\n",
    "y_test.to_csv('learning/y_test', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã\n",
    "def save_sparse_csr(filename, array):\n",
    "    np.savez(filename, data=array.data, indices=array.indices,\n",
    "             indptr=array.indptr, shape=array.shape)\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 2))\n",
    "vectorizer_posts = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 1), analyzer='word', max_features=1000)\n",
    "vectorizer_interests = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 1), analyzer='word', max_features=1000)\n",
    "vectorizer_movies = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 1), analyzer='word', max_features=1000)\n",
    "vectorizer_music = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 1), analyzer='word', max_features=1000)\n",
    "vectorizer_tv = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 1), analyzer='word', max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27208/27208 [1:09:40<00:00,  6.51it/s]\n",
      "  1%|          | 145/27208 [00:00<00:34, 778.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27208/27208 [00:33<00:00, 822.14it/s]\n",
      "  1%|          | 303/27208 [00:00<00:09, 2945.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27208/27208 [00:17<00:00, 1598.96it/s]\n",
      "  2%|‚ñè         | 414/27208 [00:00<00:06, 4092.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27208/27208 [00:11<00:00, 2366.66it/s]\n",
      "  2%|‚ñè         | 430/27208 [00:00<00:06, 4184.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27208/27208 [00:07<00:00, 3414.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27208, 5000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–∞–∑—É –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "X_train_posts = vectorizer_posts.fit_transform(tqdm(get_posts_col(df_train)))\n",
    "print(X_train_posts.shape)\n",
    "\n",
    "X_train_interests = vectorizer_interests.fit_transform(tqdm(get_interests_col(df_train)))\n",
    "print(X_train_interests.shape)\n",
    "\n",
    "X_train_movies = vectorizer_movies.fit_transform(tqdm(get_movies_col(df_train)))\n",
    "print(X_train_movies.shape)\n",
    "\n",
    "X_train_music = vectorizer_music.fit_transform(tqdm(get_music_col(df_train)))\n",
    "print(X_train_music.shape)\n",
    "\n",
    "X_train_tv = vectorizer_tv.fit_transform(tqdm(get_tv_col(df_train)))\n",
    "print(X_train_tv.shape)\n",
    "\n",
    "X_train_text = hstack([X_train_posts, X_train_interests, X_train_movies, X_train_music, X_train_tv])\n",
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø–æ–ª—É—á–∏–≤—à—É—é—Å—è –º–∞—Ç—Ä–∏—Ü—É tf-idf –¥–ª—è –ø–æ—Å—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_posts = vectorizer_posts.get_feature_names()\n",
    "features_interests = vectorizer_interests.get_feature_names()\n",
    "features_movies = vectorizer_movies.get_feature_names()\n",
    "features_music = vectorizer_music.get_feature_names()\n",
    "features_tv = vectorizer_tv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'adid', u'android', u'app', u'bitcoin', u'club', u'facebook', u'fotomagicsu', u'fotomimi', u'happy', u'instagram']\n",
      "[u'abc', u'agel', u'aimania', u'akuna', u'alfa', u'alivemax', u'ambre', u'amway', u'apple', u'aquel']\n",
      "[u'alliance', u'american', u'bad', u'big', u'black', u'capital', u'cash', u'club', u'corp', u'dead']\n",
      "[u'abba', u'accept', u'acid', u'adele', u'adriano', u'aerosmith', u'age', u'air', u'aka', u'akon']\n",
      "[u'air', u'alliance', u'allin', u'american', u'androiid', u'apple', u'aston', u'bad', u'bbc', u'big']\n"
     ]
    }
   ],
   "source": [
    "print(features_posts[:10])\n",
    "print(features_interests[:10])\n",
    "print(features_movies[:10])\n",
    "print(features_music[:10])\n",
    "print(features_tv[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–º–æ—Ä</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>music</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–≤—Å—Ç—Ä–µ—á–∞</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>—ë–ª–∫–∞</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–¥–æ–º</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  tfidf\n",
       "0         –º–æ—Ä   0.49\n",
       "1       music   0.22\n",
       "2     –≤—Å—Ç—Ä–µ—á–∞   0.22\n",
       "3  –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ   0.20\n",
       "4        —ë–ª–∫–∞   0.20\n",
       "5         –¥–æ–º   0.18"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_in_doc(X_train_posts, features_posts, 1000, top_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>—á–µ–ª–æ–≤–µ–∫</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>—Ä–æ–∂–¥–µ–Ω–∏–µ</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–∫–æ—Ç–æ—Ä—ã–π</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–æ—Ç–∫—Ä—ã—Ç–∫–∞</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–¥—Ä—É–≥</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>–≥–æ–¥</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>–∂–∏–∑–Ω—å</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>–ª—é–±–∏—Ç—å</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>–Ω–æ–≤—ã–π</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  tfidf\n",
       "0   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       "1       app   0.04\n",
       "2  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.03\n",
       "3   –∫–æ—Ç–æ—Ä—ã–π   0.03\n",
       "4  –æ—Ç–∫—Ä—ã—Ç–∫–∞   0.03\n",
       "5      –¥—Ä—É–≥   0.03\n",
       "6       –≥–æ–¥   0.03\n",
       "7     –∂–∏–∑–Ω—å   0.03\n",
       "8    –ª—é–±–∏—Ç—å   0.03\n",
       "9     –Ω–æ–≤—ã–π   0.02"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_mean_feats(X_train_posts, features_posts, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_feats_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    feature  tfidf\n",
       " 0       app   0.04\n",
       " 1      –¥—Ä—É–≥   0.03\n",
       " 2  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.03\n",
       " 3    —É–∑–Ω–∞—Ç—å   0.03\n",
       " 4    –ª—é–±–∏—Ç—å   0.03,      feature  tfidf\n",
       " 0    —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 1    –∫–æ—Ç–æ—Ä—ã–π   0.04\n",
       " 2  instagram   0.04\n",
       " 3    —Å–ø–∞—Å–∏–±–æ   0.03\n",
       " 4       –¥—Ä—É–≥   0.03,     feature  tfidf\n",
       " 0       app   0.05\n",
       " 1  –æ—Ç–∫—Ä—ã—Ç–∫–∞   0.05\n",
       " 2   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 3   –∫–æ—Ç–æ—Ä—ã–π   0.03\n",
       " 4  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.03,     feature  tfidf\n",
       " 0       app   0.06\n",
       " 1  –æ—Ç–∫—Ä—ã—Ç–∫–∞   0.06\n",
       " 2   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 3  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.03\n",
       " 4   –∫–æ—Ç–æ—Ä—ã–π   0.03,     feature  tfidf\n",
       " 0   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 1  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.04\n",
       " 2    –ª—é–±–∏—Ç—å   0.03\n",
       " 3     –∂–∏–∑–Ω—å   0.03\n",
       " 4   –∫–æ—Ç–æ—Ä—ã–π   0.03]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_by_class(X_train_posts, y_train, features_posts, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "indices not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-113149f7c8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_sparse_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learning/X_train_bag_of_words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d69d42fd5522>\u001b[0m in \u001b[0;36msave_sparse_csr\u001b[0;34m(filename, array)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_sparse_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     np.savez(filename, data=array.data, indices=array.indices,\n\u001b[0m\u001b[1;32m      4\u001b[0m              indptr=array.indptr, shape=array.shape)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: indices not found"
     ]
    }
   ],
   "source": [
    "save_sparse_csr('learning/X_train_bag_of_words', X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# —Å–æ—Ö—Ä–∞–Ω–∏–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "with open('learning/vectorizer.pk', 'wb') as fin:\n",
    "    pickle.dump(vectorizer, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function my_tokenizer at 0x7fdf1aef2e60>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer = pickle.load(open('vectorizer.pk', 'rb'))\n",
    "# vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤ –≤–∏–¥–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã\n",
    "def get_X(X_bag_of_words, df):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # –ø—Ä–∏–±–∞–≤–∏–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "    X_sex = sparse.csr_matrix(get_sex_col(df))\n",
    "\n",
    "    categorial_cols_scale = scaler.fit_transform(get_categorial_cols(df))\n",
    "    X_categorial = sparse.csr_matrix(categorial_cols_scale)\n",
    "\n",
    "    X = hstack([X_sex, X_categorial, X_bag_of_words])\n",
    "\n",
    "    print(X.shape)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 5007)\n"
     ]
    }
   ],
   "source": [
    "X_train = get_X(X_train_text, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6803/6803 [16:25<00:00,  6.91it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6803/6803 [00:07<00:00, 920.73it/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6803/6803 [00:04<00:00, 1698.38it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6803/6803 [00:02<00:00, 2550.11it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6803/6803 [00:01<00:00, 3680.27it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_posts = vectorizer_posts.transform(tqdm(get_posts_col(df_test)))\n",
    "X_test_interests = vectorizer_interests.transform(tqdm(get_interests_col(df_test)))\n",
    "X_test_movies = vectorizer_movies.transform(tqdm(get_movies_col(df_test)))\n",
    "X_test_music = vectorizer_music.transform(tqdm(get_music_col(df_test)))\n",
    "X_test_tv = vectorizer_tv.transform(tqdm(get_tv_col(df_test)))\n",
    "\n",
    "X_test_text = hstack([X_test_posts, X_test_interests, X_test_movies, X_test_music, X_test_tv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6803, 5007)\n"
     ]
    }
   ],
   "source": [
    "X_test = get_X(X_test_text, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_cv(model, param_grid, x_train, y_train):\n",
    "    grid_search = RandomizedSearchCV(model, param_grid, cv=5, scoring='accuracy', n_iter=10)\n",
    "    t_start = time.time()\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    t_end = time.time()\n",
    "    print('model {} best accuracy score is {}'.format(model.__class__.__name__, grid_search.best_score_))\n",
    "    print('time for training is {} seconds'.format(t_end - t_start))\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model MultinomialNB best accuracy score is 0.460783593061\n",
      "time for training is 3.3917350769 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha':[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 5]}\n",
    "model = MultinomialNB()\n",
    "best_model = randomized_cv(model, param_grid, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fab8d25a2a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learning/model_bayes.pk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('learning/model_bayes.pk', 'wb') as fin:\n",
    "    pickle.dump(best_model, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.467146846979\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–∏–º, —á—Ç–æ —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–µ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è, –Ω–æ –≤—Å—ë –∂–µ –ª—É—á—à–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≥–∞–¥–∞–Ω–∏—è (—É –Ω–∞—Å 5 –∫–ª–∞—Å—Å–æ–≤, –ø–æ—ç—Ç–æ–º—É –ø—Ä–∏ —Å–ª—É—á–∞–π–Ω–æ–º –≤—ã–±–æ—Ä–µ –±—ã–ª–æ –±—ã 0.2). –ï—Å—Ç—å –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ —Ç–µ–∫—Å—Ç–≤ –ø–æ—Å—Ç–∞—Ö –í–ö –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –≤–æ–∑—Ä–∞—Å—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –ø–æ—ç—Ç–æ–º—É —Ö–æ—Ä–æ—à–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–¥–µ–ª–∞—Ç—å —Ç—è–∂–µ–ª–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27208/27208 [1:08:17<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# –ø–æ–ø—Ä–æ–±—É–µ–º –±–∏–≥—Ä–∞–º–º—ã\n",
    "vectorizer_2gram = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(2, 2), analyzer='word', max_features=5000)\n",
    "X_train_bag_of_words_2gram = vectorizer_2gram.fit_transform(tqdm(get_posts_col(df_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 5007)\n"
     ]
    }
   ],
   "source": [
    "X_train_2gram = get_X(X_train_bag_of_words_2gram, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6803/6803 [17:17<00:00,  6.56it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_bag_of_words_2gram = vectorizer_2gram.transform(tqdm(get_posts_col(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6803, 5007)\n"
     ]
    }
   ],
   "source": [
    "X_test_2gram = get_X(X_test_bag_of_words_2gram, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model MultinomialNB best accuracy score is 0.475926198177\n",
      "time for training is 1.65328288078 seconds\n"
     ]
    }
   ],
   "source": [
    "model_2gram = MultinomialNB()\n",
    "best_model_2gram = randomized_cv(model_2gram, param_grid, X_train_2gram, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.474496545642\n"
     ]
    }
   ],
   "source": [
    "y_pred_2gram = best_model_2gram.predict(X_test_2gram)\n",
    "print(accuracy_score(y_test, y_pred_2gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27208/27208 [00:22<00:00, 1183.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –≤–∞—Ä–∏–∞–Ω—Ç –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –Ω–∞–º–∏ tokenizer'–∞\n",
    "vectorizer_standard = TfidfVectorizer(max_features=10000)\n",
    "X_train_bag_of_words_standard = vectorizer_standard.fit_transform(tqdm(get_posts_col(df_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27208, 10007)\n"
     ]
    }
   ],
   "source": [
    "X_train_standard = get_X(X_train_bag_of_words_standard, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6803/6803 [00:06<00:00, 1046.56it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_bag_of_words_standard = vectorizer_standard.transform(tqdm(get_posts_col(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model MultinomialNB best accuracy score is 0.488496030579\n",
      "time for training is 9.50514888763 seconds\n"
     ]
    }
   ],
   "source": [
    "model_standard = MultinomialNB()\n",
    "best_model_standard = randomized_cv(model_standard, param_grid, X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6803, 10007)\n",
      "0.492870792298\n"
     ]
    }
   ],
   "source": [
    "X_test_standard = get_X(X_test_bag_of_words_standard, df_test)\n",
    "y_pred_standard = best_model_standard.predict(X_test_standard)\n",
    "print(accuracy_score(y_test, y_pred_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1) –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ VK –∏ –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é, –Ω–æ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–æ–∑—Ä–∞—Å—Ç —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è. –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–∫–æ–ª–æ 0,5 –Ω–∞ 5 –∫–ª–∞—Å—Å–∞—Ö, —á—Ç–æ –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ 2,5 —Ä–∞–∑–∞ –ª—É—á—à–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≥–∞–¥–∞–Ω–∏—è. \n",
    "\n",
    "2) –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–∏–≥—Ä–∞–º–º (–ø–∞—Ä —Å–ª–æ–≤) –Ω–µ—Å–∫–æ–ª—å–∫–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ.\n",
    "\n",
    "3) –í—ã–±–æ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ \"–æ—Å—Ç–∞–≤–ª—è–µ–º—ã—Ö\" –≤ –Ω–∞–±–æ—Ä–µ —Å–ª–æ–≤ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ –∫–∞–∫ –≤—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª–¥—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –Ω–µ —Å–ª–∏—à–∫–æ–º –ø–æ–Ω—è—Ç–Ω–æ. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
