{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, LabelEncoder, MinMaxScaler,  Imputer\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# import cPickle as pickle\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 8)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –∫–æ—Ä–Ω—è —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏ –ª–æ–≥–∞—Ä–∏—Ñ–º–∞ \n",
    "# (Root Mean Squared Logarithmic Error (RMSLE))\n",
    "def rmsle(y, y_pred):\n",
    "    y_pred[y_pred < 0.0] = 0.0\n",
    "    log_sqr = np.square(np.log(np.add(y_pred, 1.0)) - np.log(np.add(y, 1.0)))\n",
    "    return math.sqrt(np.sum(log_sqr) / y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35517 entries, 0 to 35516\n",
      "Data columns (total 18 columns):\n",
      "political     5400 non-null float64\n",
      "country       34114 non-null object\n",
      "smoking       6264 non-null float64\n",
      "sex           35517 non-null int64\n",
      "id            35517 non-null int64\n",
      "last_name     35517 non-null object\n",
      "alcohol       6189 non-null float64\n",
      "religion      6357 non-null object\n",
      "langs         4624 non-null object\n",
      "city          32524 non-null object\n",
      "relation      14826 non-null float64\n",
      "age           35517 non-null float64\n",
      "verified      35517 non-null int64\n",
      "bdate         29173 non-null object\n",
      "first_name    35517 non-null object\n",
      "university    14826 non-null float64\n",
      "life_main     6239 non-null float64\n",
      "posts         35517 non-null object\n",
      "dtypes: float64(7), int64(3), object(8)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/vk_users_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# –∑–∞–º–µ–Ω–∏–º –Ω–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ -1\n",
    "df = df.fillna(-1)\n",
    "# –í —Å—Ç–æ–ª–±—Ü–µ university —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è id —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –ø–æ –ë–î VK. \n",
    "# –ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –µ—Å–ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω, —Ç–æ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å—Ç—å –≤—ã—Å—à–µ–µ \n",
    "# –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –∏–Ω–∞—á–µ –Ω–µ—Ç (—Ö–æ—Ç—è —Å—Ç—Ä–æ–≥–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫, –æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—Å—Ç–æ \n",
    "# –Ω–µ —É–∫–∞–∑–∞–Ω. –ù–æ –ø—Ä–∏–º–µ–º —Ç–∞–∫–æ–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ)\n",
    "df['high_education'] = df['university'].apply(lambda x: 0 if x < -0.5 else 1)\n",
    "df['age'] = df['age'].astype(int)\n",
    "df['political'] = df['political'].astype(int)\n",
    "df['smoking'] = df['smoking'].astype(int)\n",
    "df['alcohol'] = df['alcohol'].astype(int)\n",
    "df['relation'] = df['relation'].astype(int)\n",
    "df['life_main'] = df['life_main'].astype(int)\n",
    "# df['posts'] = df['posts'].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>political</th>\n",
       "      <th>country</th>\n",
       "      <th>smoking</th>\n",
       "      <th>sex</th>\n",
       "      <th>id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>religion</th>\n",
       "      <th>langs</th>\n",
       "      <th>city</th>\n",
       "      <th>relation</th>\n",
       "      <th>age</th>\n",
       "      <th>verified</th>\n",
       "      <th>bdate</th>\n",
       "      <th>first_name</th>\n",
       "      <th>university</th>\n",
       "      <th>life_main</th>\n",
       "      <th>posts</th>\n",
       "      <th>high_education</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2615791</td>\n",
       "      <td>–¢—Ä–µ—Ç—å—è–∫–æ–≤–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ú–æ—Å–∫–≤–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3.1992</td>\n",
       "      <td>–ê–Ω–∞—Å—Ç–∞—Å–∏—è</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>üå∏üå∏üå∏ #id2615791 (fashionlioness) #–º–æ–¥–µ–ª—å #—Ñ–æ—Ç–æ—Å...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>148071868</td>\n",
       "      <td>–î–º–∏—Ç—Ä–∏–µ–≤</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ö–æ—Å—Ç—Ä–æ–º–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–µ—Ä–≥–µ–π</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ö–∞—Ä–∞–Ω—Ç–∏–Ω)!!!!!!!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>54774632</td>\n",
       "      <td>–í–ª–∞—Å–æ–≤–∞</td>\n",
       "      <td>4</td>\n",
       "      <td>–ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ü–µ—Ä–º—å</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>–ê–Ω—é—Ç–∞</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>–ù–µ –≤–∞–∂–Ω–æ, —Å–∫–æ–ª—å–∫–æ –¥–≤–µ—Ä–µ–π –∑–∞–∫—Ä–æ–µ—Ç—Å—è –ø–µ—Ä–µ–¥ —Ç–≤–æ–∏–º...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>76303980</td>\n",
       "      <td>–®–∞–±–∞–ª–∫–æ–≤–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥</td>\n",
       "      <td>-1</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>–ê–Ω–∞—Å—Ç–∞—Å–∏—è</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–î—Ä—É–∑—å—è!  –Ø —Å–æ–±–∏—Ä–∞—é –±–æ–ª—å—à—É—é –ø–æ—Å—ã–ª–∫—É —Å –ø–æ–º–æ—â—å—é –¥...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>104199626</td>\n",
       "      <td>–ë–ª–µ–π—Ö</td>\n",
       "      <td>1</td>\n",
       "      <td>–ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ</td>\n",
       "      <td>['–†—É—Å—Å–∫–∏–π', 'English']</td>\n",
       "      <td>–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>6.11</td>\n",
       "      <td>–≠–¥–≥–∞—Ä</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>–ù–µ –º–æ–π —Å—Ä–µ–¥–∏ —Ç–≤–æ–∏—Ö\\n–ò—Å—Ç–∏–Ω–Ω—ã–π –∞—Ä–∏–µ—Ü. –•–∞—Ä–∞–∫—Ç–µ—Ä ‚Äî...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   political country  smoking  sex         id   last_name  alcohol  \\\n",
       "0         -1  –†–æ—Å—Å–∏—è       -1    1    2615791  –¢—Ä–µ—Ç—å—è–∫–æ–≤–∞       -1   \n",
       "1         -1  –†–æ—Å—Å–∏—è       -1    2  148071868    –î–º–∏—Ç—Ä–∏–µ–≤       -1   \n",
       "2          3  –†–æ—Å—Å–∏—è        4    1   54774632     –í–ª–∞—Å–æ–≤–∞        4   \n",
       "3         -1  –†–æ—Å—Å–∏—è       -1    1   76303980   –®–∞–±–∞–ª–∫–æ–≤–∞       -1   \n",
       "4         -1  –†–æ—Å—Å–∏—è        1    2  104199626       –ë–ª–µ–π—Ö        1   \n",
       "\n",
       "      religion                   langs             city  relation  age  \\\n",
       "0           -1                      -1           –ú–æ—Å–∫–≤–∞        -1   26   \n",
       "1           -1                      -1         –ö–æ—Å—Ç—Ä–æ–º–∞        -1   18   \n",
       "2  –ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ                      -1            –ü–µ—Ä–º—å         4  110   \n",
       "3           -1                      -1  –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥        -1   90   \n",
       "4  –ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ  ['–†—É—Å—Å–∫–∏–π', 'English']  –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥         1   26   \n",
       "\n",
       "   verified     bdate first_name  university  life_main  \\\n",
       "0         0  5.3.1992  –ê–Ω–∞—Å—Ç–∞—Å–∏—è       -1.00         -1   \n",
       "1         0        -1     –°–µ—Ä–≥–µ–π       -1.00         -1   \n",
       "2         0       6.7      –ê–Ω—é—Ç–∞        0.00          1   \n",
       "3         0       3.9  –ê–Ω–∞—Å—Ç–∞—Å–∏—è       -1.00         -1   \n",
       "4         0      6.11      –≠–¥–≥–∞—Ä        1.00          1   \n",
       "\n",
       "                                               posts  high_education  \\\n",
       "0  üå∏üå∏üå∏ #id2615791 (fashionlioness) #–º–æ–¥–µ–ª—å #—Ñ–æ—Ç–æ—Å...               0   \n",
       "1                                 –ö–∞—Ä–∞–Ω—Ç–∏–Ω)!!!!!!!!!               0   \n",
       "2  –ù–µ –≤–∞–∂–Ω–æ, —Å–∫–æ–ª—å–∫–æ –¥–≤–µ—Ä–µ–π –∑–∞–∫—Ä–æ–µ—Ç—Å—è –ø–µ—Ä–µ–¥ —Ç–≤–æ–∏–º...               1   \n",
       "3  –î—Ä—É–∑—å—è!  –Ø —Å–æ–±–∏—Ä–∞—é –±–æ–ª—å—à—É—é –ø–æ—Å—ã–ª–∫—É —Å –ø–æ–º–æ—â—å—é –¥...               0   \n",
       "4  –ù–µ –º–æ–π —Å—Ä–µ–¥–∏ —Ç–≤–æ–∏—Ö\\n–ò—Å—Ç–∏–Ω–Ω—ã–π –∞—Ä–∏–µ—Ü. –•–∞—Ä–∞–∫—Ç–µ—Ä ‚Äî...               1   \n",
       "\n",
       "   age_category  \n",
       "0             1  \n",
       "1             0  \n",
       "2             4  \n",
       "3             4  \n",
       "4             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ß—Ç–æ–±—ã –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –Ω–∞—à—É –∑–∞–¥–∞—á—É –≤ –∑–∞–¥–∞—á—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —É–º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤–æ–∑—Ä–∞—Å—Ç–∞\n",
    "# —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –≤–æ–∑—Ä–∞—Å—Ç–∞ –æ—Ç 0 –¥–æ 18; –æ—Ç 18 –¥–æ 30; –æ—Ç 30 –¥–æ 50; –æ—Ç 50 –¥–æ 70 –∏ –æ—Ç 70 –¥–æ 110 - 5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n",
    "def age_cat(age):\n",
    "    if 0 <= age <= 18:\n",
    "        return 0\n",
    "    elif 18 < age <= 30:\n",
    "        return 1\n",
    "    elif 30 < age <= 50:\n",
    "        return 2\n",
    "    elif 50 < age <= 70:\n",
    "        return 3\n",
    "    elif 70 < age <= 110:\n",
    "        return 4\n",
    "    \n",
    "df['age_category'] = df['age'].apply(lambda x: age_cat(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>political</th>\n",
       "      <th>country</th>\n",
       "      <th>smoking</th>\n",
       "      <th>sex</th>\n",
       "      <th>id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>religion</th>\n",
       "      <th>langs</th>\n",
       "      <th>city</th>\n",
       "      <th>relation</th>\n",
       "      <th>age</th>\n",
       "      <th>verified</th>\n",
       "      <th>bdate</th>\n",
       "      <th>first_name</th>\n",
       "      <th>university</th>\n",
       "      <th>life_main</th>\n",
       "      <th>posts</th>\n",
       "      <th>high_education</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15714</th>\n",
       "      <td>-1</td>\n",
       "      <td>–£–∫—Ä–∞–∏–Ω–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>128537508</td>\n",
       "      <td>–õ–µ—Ö–Ω–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–õ—å–≤–æ–≤</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>17.9.1989</td>\n",
       "      <td>–ú–∞—Ä'—è–Ω–∞</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ú–æ—è –∫–≤—ñ—Ç–æ—á–∫–∞üòòüåπüåºüå∏\\n–ö–≤—ñ—Ç–æ—á–∫–∞ –Ω–∞—à–∞, –≤—ñ—Ç–∞—î–º–æ —Ç–µ–±–µ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11666</th>\n",
       "      <td>6</td>\n",
       "      <td>–ò—Ç–∞–ª–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>132398387</td>\n",
       "      <td>–ü–µ—Ç—Ä–æ—Å—è–Ω</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ</td>\n",
       "      <td>-1</td>\n",
       "      <td>Fano</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>7.11</td>\n",
       "      <td>–ú–∞—Ä–∏–Ω–∞</td>\n",
       "      <td>16542.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–∑ –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è!!!!!\\n üòÉ –ö–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –æ—Ç–∫—Ä—ã—Ç–∫–∏ ‚ô•...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17047</th>\n",
       "      <td>-1</td>\n",
       "      <td>–ë–µ–ª–∞—Ä—É—Å—å</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>156080718</td>\n",
       "      <td>–°–æ–∫–æ–ª–æ–≤—Å–∫–∞—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ú–∏–Ω—Å–∫</td>\n",
       "      <td>-1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>–ï–ª–µ–Ω–∞</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–í—Å–µ—Ö —Å –ù–æ–≤—ã–º –≥–æ–¥–æ–º –°–æ–±–∞–∫–∏!!!  –°—á–∞—Å—Ç—å—è,  –õ—é–±–≤–∏,...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28715</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3687543</td>\n",
       "      <td>–ò–≥–æ–Ω–∏–Ω–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>–≤–µ—Ä—é –≤ —Å–µ–±—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>–£–ª—å—è–Ω–æ–≤—Å–∫</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>–ê–Ω–Ω–∞</td>\n",
       "      <td>871.00</td>\n",
       "      <td>6</td>\n",
       "      <td>–ê–∫—Ç—É–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ –ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ —Ñ–æ—Ç–æ—Å–µ—Å—Å–∏–∏ –∏ —Ñ–æ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27703</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>819833</td>\n",
       "      <td>–ó–∞–π—Ü–µ–≤–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>–≤–µ—Ä—é</td>\n",
       "      <td>-1</td>\n",
       "      <td>–¢—é–º–µ–Ω—å</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>27.11</td>\n",
       "      <td>–ö—Å–µ–Ω–∏—è</td>\n",
       "      <td>862.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ù–∞ —É–ª–∏—Ü–µ –±–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∫—Ä–∞—Å–æ—Ç–∞üòçüòç –∫–∞–∫ —É –≤–∞—Å –ø–æ—Å–ª...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       political   country  smoking  sex         id    last_name  alcohol  \\\n",
       "15714         -1   –£–∫—Ä–∞–∏–Ω–∞       -1    1  128537508   –õ–µ—Ö–Ω–æ–≤—Å—å–∫–∞       -1   \n",
       "11666          6    –ò—Ç–∞–ª–∏—è       -1    1  132398387     –ü–µ—Ç—Ä–æ—Å—è–Ω       -1   \n",
       "17047         -1  –ë–µ–ª–∞—Ä—É—Å—å       -1    1  156080718  –°–æ–∫–æ–ª–æ–≤—Å–∫–∞—è       -1   \n",
       "28715         -1    –†–æ—Å—Å–∏—è       -1    1    3687543      –ò–≥–æ–Ω–∏–Ω–∞       -1   \n",
       "27703         -1    –†–æ—Å—Å–∏—è       -1    1     819833      –ó–∞–π—Ü–µ–≤–∞       -1   \n",
       "\n",
       "          religion langs       city  relation  age  verified      bdate  \\\n",
       "15714           -1    -1      –õ—å–≤–æ–≤        -1   30         0  17.9.1989   \n",
       "11666  –ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ    -1       Fano         1   54         0       7.11   \n",
       "17047           -1    -1      –ú–∏–Ω—Å–∫        -1   50         0        5.7   \n",
       "28715  –≤–µ—Ä—é –≤ —Å–µ–±—è    -1  –£–ª—å—è–Ω–æ–≤—Å–∫         7   42         0       13.3   \n",
       "27703         –≤–µ—Ä—é    -1     –¢—é–º–µ–Ω—å         4   34         0      27.11   \n",
       "\n",
       "      first_name  university  life_main  \\\n",
       "15714    –ú–∞—Ä'—è–Ω–∞       -1.00         -1   \n",
       "11666     –ú–∞—Ä–∏–Ω–∞    16542.00         -1   \n",
       "17047      –ï–ª–µ–Ω–∞       -1.00         -1   \n",
       "28715       –ê–Ω–Ω–∞      871.00          6   \n",
       "27703     –ö—Å–µ–Ω–∏—è      862.00         -1   \n",
       "\n",
       "                                                   posts  high_education  \\\n",
       "15714  –ú–æ—è –∫–≤—ñ—Ç–æ—á–∫–∞üòòüåπüåºüå∏\\n–ö–≤—ñ—Ç–æ—á–∫–∞ –Ω–∞—à–∞, –≤—ñ—Ç–∞—î–º–æ —Ç–µ–±–µ ...               0   \n",
       "11666  –∑ –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è!!!!!\\n üòÉ –ö–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –æ—Ç–∫—Ä—ã—Ç–∫–∏ ‚ô•...               1   \n",
       "17047  –í—Å–µ—Ö —Å –ù–æ–≤—ã–º –≥–æ–¥–æ–º –°–æ–±–∞–∫–∏!!!  –°—á–∞—Å—Ç—å—è,  –õ—é–±–≤–∏,...               0   \n",
       "28715  –ê–∫—Ç—É–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ –ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ —Ñ–æ—Ç–æ—Å–µ—Å—Å–∏–∏ –∏ —Ñ–æ...               1   \n",
       "27703  –ù–∞ —É–ª–∏—Ü–µ –±–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∫—Ä–∞—Å–æ—Ç–∞üòçüòç –∫–∞–∫ —É –≤–∞—Å –ø–æ—Å–ª...               1   \n",
       "\n",
       "       age_category  \n",
       "15714             1  \n",
       "11666             3  \n",
       "17047             2  \n",
       "28715             2  \n",
       "27703             2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>political</th>\n",
       "      <th>country</th>\n",
       "      <th>smoking</th>\n",
       "      <th>sex</th>\n",
       "      <th>id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>religion</th>\n",
       "      <th>langs</th>\n",
       "      <th>city</th>\n",
       "      <th>relation</th>\n",
       "      <th>age</th>\n",
       "      <th>verified</th>\n",
       "      <th>bdate</th>\n",
       "      <th>first_name</th>\n",
       "      <th>university</th>\n",
       "      <th>life_main</th>\n",
       "      <th>posts</th>\n",
       "      <th>high_education</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>30163255</td>\n",
       "      <td>–ö—É–∑–∏–Ω—Å–∫–∏–π</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–æ—á–∏</td>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>15.8.1984</td>\n",
       "      <td>–í–∏—Ç–∞–ª–∏–∫</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ó–∞–∫—Ä—ã–ª —Å–æ—Ä–µ–≤–Ω–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Å–µ–∑–æ–Ω 17–≥–æ –≥–æ–¥–∞. \\n–°—Ç–∞...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>35057592</td>\n",
       "      <td>–ü—å–µ—Ö–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥</td>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°—Ç–∞—Å</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–Ø –¥–æ–ª–≥–æ –∂–¥–∞–ª- –ö–æ–≥–¥–∞ –ø—Ä–∏–¥–µ—Ç –µ—ë —á–µ—Ä–µ–¥? –≤–µ–¥—å —ç—Ç–æ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29722</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>116910037</td>\n",
       "      <td>–ê–ª–¥–æ—à–∏–Ω–∞</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥</td>\n",
       "      <td>-1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>20.2.1962</td>\n",
       "      <td>–ï–ª–µ–Ω–∞</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ï–ª–µ–Ω–∞ –ø—Ä–æ–≥–Ω–∞–ª–∞ –∏–∑ —Ä–æ—â–∏—Ü—ã –ª—é–±–∏—Ç–µ–ª–µ–π —è–≥–æ–¥ - –º–µ–¥–≤...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33234</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>35303</td>\n",
       "      <td>–í–∞—Ä–ª–∞–º–æ–≤</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥</td>\n",
       "      <td>-1</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>13.11.1930</td>\n",
       "      <td>–õ—ë—à–∞</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–° –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è!!)\\n–§–æ—Ä–¥, –≥–æ–≤–æ—Ä–∏—à—å? –ê –ø—Ä–∏–≤–æ–¥ –∫...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15361</th>\n",
       "      <td>-1</td>\n",
       "      <td>–†–æ—Å—Å–∏—è</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>3159625</td>\n",
       "      <td>–°—Ç–∏–≤</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>666.5</td>\n",
       "      <td>–ù–∞–≤–æ–ª–æ—á–∫–∞</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>–°–ö–ê–ß–ò–í–ê–ï–ú –ò –°–õ–£–®–ê–ï–ú –ù–ê–® MIXTAPE –ó–û–ù–ê 812!\\n\\n–°...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       political country  smoking  sex         id  last_name  alcohol  \\\n",
       "7339          -1  –†–æ—Å—Å–∏—è       -1    2   30163255  –ö—É–∑–∏–Ω—Å–∫–∏–π       -1   \n",
       "9058          -1  –†–æ—Å—Å–∏—è       -1    2   35057592      –ü—å–µ—Ö–∞       -1   \n",
       "29722         -1  –†–æ—Å—Å–∏—è       -1    1  116910037   –ê–ª–¥–æ—à–∏–Ω–∞       -1   \n",
       "33234         -1  –†–æ—Å—Å–∏—è       -1    2      35303   –í–∞—Ä–ª–∞–º–æ–≤       -1   \n",
       "15361         -1  –†–æ—Å—Å–∏—è       -1    2    3159625       –°—Ç–∏–≤       -1   \n",
       "\n",
       "      religion langs             city  relation  age  verified       bdate  \\\n",
       "7339        -1    -1             –°–æ—á–∏        -1   34         0   15.8.1984   \n",
       "9058        -1    -1  –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥        -1   34         1          -1   \n",
       "29722       -1    -1  –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥        -1   54         0   20.2.1962   \n",
       "33234       -1    -1  –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥        -1   86         0  13.11.1930   \n",
       "15361       -1    -1  –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥        -1    6         0       666.5   \n",
       "\n",
       "      first_name  university  life_main  \\\n",
       "7339     –í–∏—Ç–∞–ª–∏–∫       -1.00         -1   \n",
       "9058        –°—Ç–∞—Å       -1.00         -1   \n",
       "29722      –ï–ª–µ–Ω–∞       -1.00         -1   \n",
       "33234       –õ—ë—à–∞       -1.00         -1   \n",
       "15361  –ù–∞–≤–æ–ª–æ—á–∫–∞       -1.00         -1   \n",
       "\n",
       "                                                   posts  high_education  \\\n",
       "7339   –ó–∞–∫—Ä—ã–ª —Å–æ—Ä–µ–≤–Ω–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Å–µ–∑–æ–Ω 17–≥–æ –≥–æ–¥–∞. \\n–°—Ç–∞...               0   \n",
       "9058   –Ø –¥–æ–ª–≥–æ –∂–¥–∞–ª- –ö–æ–≥–¥–∞ –ø—Ä–∏–¥–µ—Ç –µ—ë —á–µ—Ä–µ–¥? –≤–µ–¥—å —ç—Ç–æ ...               0   \n",
       "29722  –ï–ª–µ–Ω–∞ –ø—Ä–æ–≥–Ω–∞–ª–∞ –∏–∑ —Ä–æ—â–∏—Ü—ã –ª—é–±–∏—Ç–µ–ª–µ–π —è–≥–æ–¥ - –º–µ–¥–≤...               0   \n",
       "33234  –° –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è!!)\\n–§–æ—Ä–¥, –≥–æ–≤–æ—Ä–∏—à—å? –ê –ø—Ä–∏–≤–æ–¥ –∫...               0   \n",
       "15361  –°–ö–ê–ß–ò–í–ê–ï–ú –ò –°–õ–£–®–ê–ï–ú –ù–ê–® MIXTAPE –ó–û–ù–ê 812!\\n\\n–°...               0   \n",
       "\n",
       "       age_category  \n",
       "7339              2  \n",
       "9058              2  \n",
       "29722             3  \n",
       "33234             4  \n",
       "15361             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–∏–º –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "df_train.to_csv('learning/df_train.csv', sep='\\t', encoding='utf-8')\n",
    "df_test.to_csv('learning/df_test.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–º—ã—Å–ª –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö sex, political, smoking, alcohol, relation, life_main —Å–ª–µ–¥—É—é—â–∏–π (–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è API VK):\n",
    "\n",
    "1) sex - –ø–æ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n",
    "1 - –∂–µ–Ω—Å–∫–∏–π;\n",
    "2 - –º—É–∂—Å–∫–æ–π;\n",
    "0 - –ø–æ–ª –Ω–µ —É–∫–∞–∑–∞–Ω\n",
    "\n",
    "2) political - –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è:\n",
    "\n",
    "1 - –∫–æ–º–º—É–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ;\n",
    "2 - —Å–æ—Ü–∏–∞–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ;\n",
    "3 - —É–º–µ—Ä–µ–Ω–Ω—ã–µ;\n",
    "4 - –ª–∏–±–µ—Ä–∞–ª—å–Ω—ã–µ;\n",
    "5 - –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ;\n",
    "6 - –º–æ–Ω–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ;\n",
    "7 - —É–ª—å—Ç—Ä–∞–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ;\n",
    "8 - –∏–Ω–¥–∏—Ñ—Ñ–∏—Ä–µ–Ω—Ç–Ω—ã–µ;\n",
    "9 - –ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω—Å–∫–∏–µ;\n",
    "\n",
    "3) smoking, alcohol - –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∫—É—Ä–µ–Ω–∏—é, –∞–ª–∫–æ–≥–æ–ª—é:\n",
    "\n",
    "1 - —Ä–µ–∑–∫–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ;\n",
    "2 - –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ;\n",
    "3 - –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–Ω–æ–µ;\n",
    "4 - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ;\n",
    "5 - –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ;\n",
    "\n",
    "4) relation - —Å–µ–º–µ–π–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ:\n",
    "\n",
    "1 - –Ω–µ –∂–µ–Ω–∞—Ç/–Ω–µ –∑–∞–º—É–∂–µ–º;\n",
    "2 - –µ—Å—Ç—å –¥—Ä—É–≥/–µ—Å—Ç—å –ø–æ–¥—Ä—É–≥–∞;\n",
    "3 - –ø–æ–º–æ–ª–≤–ª–µ–Ω/–ø–æ–º–æ–ª–≤–ª–µ–Ω–∞;\n",
    "4 - –∂–µ–Ω–∞—Ç/–∑–∞–º—É–∂–µ–º;\n",
    "5 - –≤—Å—ë —Å–ª–æ–∂–Ω–æ;\n",
    "6 - –≤ –∞–∫—Ç–∏–≤–Ω–æ–º –ø–æ–∏—Å–∫–µ;\n",
    "7 - –≤–ª—é–±–ª—ë–Ω/–≤–ª—é–±–ª–µ–Ω–∞;\n",
    "8 - –≤ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –±—Ä–∞–∫–µ;\n",
    "0 - –Ω–µ —É–∫–∞–∑–∞–Ω–æ;\n",
    "\n",
    "5) life_main - –≥–ª–∞–≤–Ω–æ–µ –≤ –∂–∏–∑–Ω–∏:\n",
    "\n",
    "1 - —Å–µ–º—å—è –∏ –¥–µ—Ç–∏;\n",
    "2 - –∫–∞—Ä—å–µ—Ä–∞ –∏ –¥–µ–Ω—å–≥–∏;\n",
    "3 - —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è –∏ –æ—Ç–¥—ã—Ö;\n",
    "4 - –Ω–∞—É–∫–∞ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è;\n",
    "5 - —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–∏—Ä–∞;\n",
    "6 - —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ;\n",
    "7 - –∫—Ä–∞—Å–æ—Ç–∞ –∏ –∏—Å–∫—É—Å—Å—Ç–≤–æ;\n",
    "8 - —Å–ª–∞–≤–∞ –∏ –≤–ª–∏—è–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–æ–∑—Ä–∞—Å—Ç (–ø–æ –¥–∞–Ω–Ω—ã–º VK (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å —Å –æ—à–∏–±–∫–∞–º–∏: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –∫–∞–∫ –æ–Ω —Ç–∞–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è)) –ø–æ –ø–æ—Å—Ç–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ–≥–æ –ø–æ–ª—É (–ø–æ–ª —É–∫–∞–∑–∞–Ω –≤—Å–µ–≥–¥–∞) –∏ —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ personal, –∞ —Ç–∞–∫–∂–µ –ø–æ –Ω–∞–ª–∏—á–∏—é –≤—ã—Å—à–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –§—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_en = stopwords.words('english')\n",
    "stopwords_ru = stopwords.words('russian')\n",
    "stopwords_ge = stopwords.words('german')\n",
    "\n",
    "stopwords_all = stopwords_en + stopwords_ru + stopwords_ge\n",
    "\n",
    "# –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±—É–∫–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º —É–¥–∞–ª—è—Ç—å –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "additional_stopwords = \\\n",
    "[u'https', u'vk', u'com', u'id', u'ph', u'–¥—Ä', u'—Å–≤', u'ff', u'la', u'—ç—Ç–æ', \\\n",
    " u'de', u'pa', u'bb', u'p', u'—É–ª', u'–∏–Ω', u'http', u'ru', u'md', u'x', \\\n",
    " u'ft', u'—Å–±', u'b', u'–∫', u'www', u'youtube', u'–∫–∞', u'v', u'g', u'goo', u'gl', \\\n",
    " u'eu', u'u', u'te', u'un', u'–≤–∫', u'w', u'ly', u'su', u'bu', u'vl', u'—ç—Ç', u'r', u'e', \\\n",
    " u'—Å–≤–æ–π', u'–µ—â—ë', u'–º–æ–π', u'–≤–µ—Å—å', u'–¥–Ω—ë–º', u'youtu', u'—Ç–≤–æ–π', u'–Ω–∞—à', u'–≤–∞—à', u'—Ç–æ—Ç', u'—ç—Ç–æ—Ç']\n",
    "\n",
    "stopwords_all = stopwords_all + additional_stopwords\n",
    "\n",
    "# –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–¥–∞–ª—è–µ–º—ã–µ –ø–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–≤–∞\n",
    "delete_words = [u'—Å–≤–æ–π', u'–µ—â—ë', u'–º–æ–π', u'–≤–µ—Å—å', u'–¥–Ω—ë–º', u'youtu', u'—Ç–≤–æ–π', u'–Ω–∞—à', u'–≤–∞—à', u'—Ç–æ—Ç', u'—ç—Ç–æ—Ç']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫—É pymorphy2, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    return morph.parse(text)[0].normal_form\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    # –æ—á–∏—Å—Ç–∫–∞ –æ—Ç html-—Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # –≤—ã–¥–µ–ª–µ–Ω–∏–µ —Å–º–∞–π–ª–æ–≤\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—Å–ª–æ–≤–∞—Ä–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    text = re.sub(r'[\\W]+', ' ', text, flags=re.U) + ' '.join(emoticons).replace('-', '')\n",
    "    # —É–¥–∞–ª–∏–º —Ç–∞–∫–∂–µ –≤—Å–µ —Ü–∏—Ñ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—Ä—è–¥ –ª–∏ –ø–æ–ª–µ–∑–Ω—ã –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞\n",
    "    text = re.sub(r'\\d+', '', text, flags=re.U)\n",
    "    # —É–¥–∞–ª–∏–º –¥–≤–∞ –∏–ª–∏ –±–æ–ª–µ–µ –ø—Ä–æ–±–µ–ª–æ–≤\n",
    "    text = re.sub(r'[ ]{2,}', '', text, flags=re.U)\n",
    "    # —É–¥–∞–ª–∏–º –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è\n",
    "    text = re.sub(r'[_]+', '', text, flags=re.U)\n",
    "    # —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–±–µ–ª–∞–º –∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "    tokenized = [w for w in text.split() if w not in stopwords_all]\n",
    "    tokenized = [re.sub(r\"\\W\", \"\", w, flags=re.U) for w in tokenized]\n",
    "    # –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "    tokenized = [lemmatization(w) for w in tokenized]\n",
    "    # —É–¥–∞–ª–∏–º –≤—Å–µ —Å–ª–æ–≤–∞ –∏–∑ –æ–¥–Ω–æ–π –∏ –¥–≤—É—Ö –±—É–∫–≤. –í—Ä—è–¥ –ª–∏ –æ–Ω–∏ –Ω–µ—Å—É—Ç –±–æ–ª—å—à–æ–π —Å–º—ã—Å–ª. \n",
    "    # –¢–∞–∫–∂–µ —É–¥–∞–ª–∏–º \"—Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã\"\n",
    "    tokenized = [w for w in tokenized if len(w) > 2 and w not in delete_words]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posts_col(df):\n",
    "    return df[['posts']]\n",
    "\n",
    "def get_sex_col(df):\n",
    "    return df[['sex']]\n",
    "\n",
    "def get_categorial_cols(df):\n",
    "    return df[['high_education', 'political', 'smoking', 'alcohol', 'relation', 'life_main']]\n",
    "\n",
    "vec = make_union(*[\n",
    "    make_pipeline(FunctionTransformer(get_categorial_cols, validate=False), MinMaxScaler()),\n",
    "    make_pipeline(FunctionTransformer(get_posts_col, validate=False)), CountVectorizer(tokenizer=my_tokenizer)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° pipeline'–æ–º —á—Ç–æ-—Ç–æ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–æ–ª–±–µ—Ü —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28413,)\n",
      "(7104,)\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['age_category']\n",
    "y_test = df_test['age_category']\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.to_csv('learning/y_train', sep='\\t')\n",
    "y_test.to_csv('learning/y_test', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã\n",
    "def save_sparse_csr(filename, array):\n",
    "    np.savez(filename, data=array.data, indices=array.indices,\n",
    "             indptr=array.indptr, shape=array.shape)\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 2))\n",
    "vectorizer = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(1, 1), analyzer='word', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28413/28413 [38:22<00:00, 12.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28413, 4694)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bag_of_words = vectorizer.fit_transform(tqdm(df_train['posts']))\n",
    "X_train_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò—Å—Å–ª–µ–¥—É–µ–º –ø–æ–ª—É—á–∏–≤—à—É—é—Å—è –º–∞—Ç—Ä–∏—Ü—É tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–∫–ª—É–±</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–¥–µ–≤–æ—á–∫–∞</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–º—É–∂</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–¥–µ–Ω—å–≥–∞</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  tfidf\n",
       "0     love   0.61\n",
       "1    happy   0.36\n",
       "2     –∫–ª—É–±   0.19\n",
       "3  –¥–µ–≤–æ—á–∫–∞   0.14\n",
       "4      –º—É–∂   0.14\n",
       "5   –¥–µ–Ω—å–≥–∞   0.13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_in_doc(X_train_bag_of_words, features, 1000, top_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>—á–µ–ª–æ–≤–µ–∫</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>—Ä–æ–∂–¥–µ–Ω–∏–µ</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–∫–æ—Ç–æ—Ä—ã–π</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–æ—Ç–∫—Ä—ã—Ç–∫–∞</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–¥—Ä—É–≥</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>–≥–æ–¥</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>–∂–∏–∑–Ω—å</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>–ª—é–±–∏—Ç—å</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>–Ω–æ–≤—ã–π</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  tfidf\n",
       "0       app   0.04\n",
       "1   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       "2  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.03\n",
       "3   –∫–æ—Ç–æ—Ä—ã–π   0.03\n",
       "4  –æ—Ç–∫—Ä—ã—Ç–∫–∞   0.03\n",
       "5      –¥—Ä—É–≥   0.03\n",
       "6       –≥–æ–¥   0.03\n",
       "7     –∂–∏–∑–Ω—å   0.03\n",
       "8    –ª—é–±–∏—Ç—å   0.03\n",
       "9     –Ω–æ–≤—ã–π   0.03"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_mean_feats(X_train_bag_of_words, features, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_feats_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    feature  tfidf\n",
       " 0       app   0.04\n",
       " 1    —É–∑–Ω–∞—Ç—å   0.03\n",
       " 2  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.03\n",
       " 3      –¥—Ä—É–≥   0.03\n",
       " 4    –ª—é–±–∏—Ç—å   0.03,      feature  tfidf\n",
       " 0    —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 1  instagram   0.04\n",
       " 2    –∫–æ—Ç–æ—Ä—ã–π   0.04\n",
       " 3    —Å–ø–∞—Å–∏–±–æ   0.03\n",
       " 4       –¥—Ä—É–≥   0.03,     feature  tfidf\n",
       " 0       app   0.06\n",
       " 1  –æ—Ç–∫—Ä—ã—Ç–∫–∞   0.05\n",
       " 2   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 3   –∫–æ—Ç–æ—Ä—ã–π   0.04\n",
       " 4       –≥–æ–¥   0.03,     feature  tfidf\n",
       " 0       app   0.07\n",
       " 1  –æ—Ç–∫—Ä—ã—Ç–∫–∞   0.06\n",
       " 2   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 3   –∫–æ—Ç–æ—Ä—ã–π   0.03\n",
       " 4  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.03,     feature  tfidf\n",
       " 0   —á–µ–ª–æ–≤–µ–∫   0.04\n",
       " 1  —Ä–æ–∂–¥–µ–Ω–∏–µ   0.04\n",
       " 2    –ª—é–±–∏—Ç—å   0.04\n",
       " 3   –∫–æ—Ç–æ—Ä—ã–π   0.03\n",
       " 4     –∂–∏–∑–Ω—å   0.03]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_by_class(X_train_bag_of_words, y_train, features, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_sparse_csr('learning/X_train_bag_of_words', X_train_bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# —Å–æ—Ö—Ä–∞–Ω–∏–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "with open('learning/vectorizer.pk', 'wb') as fin:\n",
    "    pickle.dump(vectorizer, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function my_tokenizer at 0x7fdf1aef2e60>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer = pickle.load(open('vectorizer.pk', 'rb'))\n",
    "# vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤ –≤–∏–¥–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã\n",
    "def get_X(X_bag_of_words, df):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # –ø—Ä–∏–±–∞–≤–∏–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "    X_sex = sparse.csr_matrix(get_sex_col(df))\n",
    "\n",
    "    categorial_cols_scale = scaler.fit_transform(get_categorial_cols(df))\n",
    "    X_categorial = sparse.csr_matrix(categorial_cols_scale)\n",
    "\n",
    "    X = hstack([X_sex, X_categorial, X_bag_of_words])\n",
    "\n",
    "    print(X.shape)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28413, 4701)\n"
     ]
    }
   ],
   "source": [
    "X_train = get_X(X_train_bag_of_words, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7104/7104 [10:06<00:00, 11.72it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_bag_of_words = vectorizer.transform(tqdm(df_test['posts']))\n",
    "save_sparse_csr('learning/X_test_bag_of_words', X_test_bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7104, 4701)\n"
     ]
    }
   ],
   "source": [
    "X_test = get_X(X_test_bag_of_words, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomized_cv(model, param_grid, x_train, y_train):\n",
    "    grid_search = RandomizedSearchCV(model, param_grid, cv=5, scoring='accuracy', n_iter=10)\n",
    "    t_start = time.time()\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    t_end = time.time()\n",
    "    print('model {} best accuracy score is {}'.format(model.__class__.__name__, grid_search.best_score_))\n",
    "    print('time for training is {} seconds'.format(t_end - t_start))\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model MultinomialNB best accuracy score is 0.4875233167916095\n",
      "time for training is 6.673130989074707 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha':[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 5]}\n",
    "model = MultinomialNB()\n",
    "best_model = randomized_cv(model, param_grid, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fab8d25a2a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learning/model_bayes.pk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('learning/model_bayes.pk', 'wb') as fin:\n",
    "    pickle.dump(best_model, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.485923423423\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–∏–º, —á—Ç–æ —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–µ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è, –Ω–æ –≤—Å—ë –∂–µ –ª—É—á—à–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≥–∞–¥–∞–Ω–∏—è (—É –Ω–∞—Å 5 –∫–ª–∞—Å—Å–æ–≤, –ø–æ—ç—Ç–æ–º—É –ø—Ä–∏ —Å–ª—É—á–∞–π–Ω–æ–º –≥–∞–¥–∞–Ω–∏–∏ –±—ã–ª–æ –±—ã 0.2). –ï—Å—Ç—å –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ —Ç–µ–∫—Å—Ç–≤ –ø–æ—Å—Ç–∞—Ö –í–ö –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –≤–æ–∑—Ä–∞—Å—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –ø–æ—ç—Ç–æ–º—É —Ö–æ—Ä–æ—à–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–¥–µ–ª–∞—Ç—å —Ç—è–∂–µ–ª–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28413/28413 [39:27<00:00, 12.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# –ø–æ–ø—Ä–æ–±—É–µ–º –±–∏–≥—Ä–∞–º–º—ã\n",
    "vectorizer_2gram = TfidfVectorizer(tokenizer=my_tokenizer, ngram_range=(2, 2), analyzer='word', max_features=5000)\n",
    "X_train_bag_of_words_2gram = vectorizer_2gram.fit_transform(tqdm(df_train['posts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28413, 31)\n"
     ]
    }
   ],
   "source": [
    "X_train_2gram = get_X(X_train_bag_of_words_2gram, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7104/7104 [09:41<00:00, 12.22it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_bag_of_words_2gram = vectorizer_2gram.transform(tqdm(df_test['posts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7104, 31)\n"
     ]
    }
   ],
   "source": [
    "X_test_2gram = get_X(X_test_bag_of_words_2gram, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model MultinomialNB best accuracy score is 0.4162883187273431\n",
      "time for training is 0.4641273021697998 seconds\n"
     ]
    }
   ],
   "source": [
    "model_2gram = MultinomialNB()\n",
    "best_model_2gram = randomized_cv(model_2gram, param_grid, X_train_2gram, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.420467342342\n"
     ]
    }
   ],
   "source": [
    "y_pred_2gram = best_model_2gram.predict(X_test_2gram)\n",
    "print(accuracy_score(y_test, y_pred_2gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
