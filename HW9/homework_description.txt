Сбор текстовых данных и их использование в построении модели.

1. Собрать текстовые данные пользователей vk.com (посты), а так же информацию о пользователях (пол, возраст, семейное положение, наличие высшего образования и пр.)
Выбрать характеристику пользователя для предсказания. Характеристика не должна быть всегда известна. Например, в vk.com пользователи часто скрывают возраст, а так же не заполняют часть полей.
При сборе данных учесть распределения. Например, при построении модели, предсказывающей возраст, нужно собирать данные пользователей разных возрастов. 
2. Отложить часть данных (пользователей) для итоговой оценки качества. Никак не использовать эти данные для анализа и обучения модели.
3. Зафиксировать метрику. Подобрать модель по этой метрике. 
  * Преобразовать данные
  * Осуществить подбор признаков
  * Осуществить подбор модели и параметров

При подборе признаков проработать варианты:
  * стеммизация слов
  * лемматизация слов
  * биграммы и триграммы слов
  * триграммы символов
  (*) упоминания сущностей
  (*) тональность постов
  ...

4. Выполнить предсказание на отложенных данных, оценить качество по той же метрике
5(*). Запустить в боевом окружении. 
Предлагается простой вариант - запустить своего бота в телеграм.
Бот принимает на вход ссылку на аккаунт пользователя и возвращает предсказание характеристики.
 

Задание рекомендуется делать итерациями, постепенно усложняя. Необходимо иметь MVP и его улучшать.
1. Сбор данных десяти пользователей
2. Преобразование данных в признаки с помощью CountVectorizer
3. Построение NaiveBayes
4. Запуск бота
5. Повтор пунктов 1-4 с постепенным усложнением каждого из пунктов. Пункт 1 в усложненном виде рекомендуется реализовать так, чтобы не требовалось его повторное выполнение. Пользователи редко обновляют аккаунты, поэтому к API можно обращаться как можно реже, сохраняя все данные и не запрашивая их повторно.

P.S. можно обратиться к статистике:
http://blog.br-analytics.ru/sotsialnye-seti-v-rossii-leto-2017-tsifry-i-trendy/
нужно проверять
