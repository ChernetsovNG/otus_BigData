{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=0.99,\n",
    "                 criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split  # ограничение минимального числа объектов в листе\n",
    "        self.max_depth = max_depth  # параметр max_depth ограничивает глубину дерева\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    # Набор функция для вычисления меры \"нечистоты\" (Impurity)\n",
    "    # или меры неоднородности при разделении в узле дерева на левый и правый узлы\n",
    "    # В функциях используются следующие входные параметры:\n",
    "    # l_c == l_class_count - количество образцов первого и второго класса в левой части разделённого массива\n",
    "    # l_s == l_sizes - размер левой части\n",
    "    # r_c == r_class_count - количество образцов первого и второго класса в правой части разделённого массива\n",
    "    # r_s == r_sizes - размер правой части\n",
    "    # передаются массивы таких значений для всех возможных разбиений по местам изменения целевого признака\n",
    "    # возвращают значения меры неоднородности для различных возможных разбиений\n",
    "    \n",
    "    # мера неоднородности Джини\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # Общий размер левой и правой части\n",
    "        size_all = l_s[0, 0] + r_s[0, 0]\n",
    "        # Доля образцов, котороые принадлежат классу 1 в левом узле\n",
    "        p_1_left = l_c[:, 0] / l_s[:, 0]\n",
    "        # Доля образцов, котороые принадлежат классу 2 в левом узле\n",
    "        p_2_left = l_c[:, 1] / l_s[:, 0]\n",
    "        # Мера Джини для левого узла\n",
    "        gini_left = 1.0 - np.square(p_1_left) - np.square(p_2_left)\n",
    "        # Аналогично для правого узла\n",
    "        p_1_right = r_c[:, 0] / r_s[:, 0]\n",
    "        p_2_right = r_c[:, 1] / r_s[:, 0]\n",
    "        gini_right = 1.0 - np.square(p_1_right) - np.square(p_2_right)\n",
    "       \n",
    "        gini_sum = (l_s[:, 0] / size_all) * gini_left + (r_s[:, 0] / size_all) * gini_right      \n",
    "        return gini_sum\n",
    "    \n",
    "    \n",
    "    # Информационная энтропия\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        threshold = 1e-10\n",
    "        # Общий размер левой и правой части\n",
    "        size_all = l_s[0, 0] + r_s[0, 0]\n",
    "        # Доля образцов, котороые принадлежат классу 1 в левом узле\n",
    "        p_1_left = l_c[:, 0] / l_s[:, 0]\n",
    "        # Доля образцов, котороые принадлежат классу 2 в левом узле\n",
    "        p_2_left = l_c[:, 1] / l_s[:, 0]\n",
    "        # Энтропия для левого узла\n",
    "        entropy_left = -1.0 * (p_1_left * np.log2(np.clip(p_1_left, threshold, 1.0 - threshold)) +\n",
    "                               p_2_left * np.log2(np.clip(p_2_left, threshold, 1.0 - threshold)))\n",
    "        # Аналогично для правого узла\n",
    "        p_1_right = r_c[:, 0] / r_s[:, 0]\n",
    "        p_2_right = r_c[:, 1] / r_s[:, 0]\n",
    "        entropy_right = -1.0 * (p_1_right * np.log2(np.clip(p_1_right, threshold, 1.0 - threshold)) +\n",
    "                                p_2_right * np.log2(np.clip(p_2_right, threshold, 1.0 - threshold)))\n",
    "       \n",
    "        entropy_sum = (l_s[:, 0] / size_all) * entropy_left + (r_s[:, 0] / size_all) * entropy_right      \n",
    "        return entropy_sum\n",
    "\n",
    "    \n",
    "    # Ошибка классификации (misclassification error)\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # Общий размер левой и правой части\n",
    "        size_all = l_s[0, 0] + r_s[0, 0]\n",
    "        # Неоднородность левой части после разделения\n",
    "        # (выбираем преобладающий класс в левой части и делим на размер левой части == максимальная\n",
    "        # вероятность класса в левой части после разделения)\n",
    "        ME_left = 1.0 - np.max(l_c, axis=1) / l_s[:,0]\n",
    "        # Неоднородность правой части после разделения\n",
    "        ME_right = 1.0 - np.max(r_c, axis=1) / r_s[:,0]\n",
    "        \n",
    "        # Общая неоднородность левой и правой частей\n",
    "        ME_sum = (l_s[:, 0] / size_all) * ME_left + (r_s[:, 0] / size_all) * ME_right   \n",
    "        return ME_sum\n",
    "\n",
    "    \n",
    "    # Дла разделения в узлах могут быть выбираны не все признаки, а только несколько из них\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return # Ваш код\n",
    "      \n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return # Ваш код\n",
    "\n",
    "    \n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids\n",
    " \n",
    "\n",
    "    # Выполняет сортировку признака по возрастанию. На вход передаётся один признак x\n",
    "    def __sort_samples(self, x, y):  \n",
    "        sorted_idx = x.argsort() \n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    \n",
    "    # метод делит выборку по пороговому значению\n",
    "    # выбираются те строки, где значение признака feature_id больше порогового значения (left_mask),\n",
    "    # и те строки, где значение признака feature_id меньше порогового значения (rigth_mask)\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    \n",
    "    # Метод находит пороги (т.е. значения признака, при которых целевой признак y\n",
    "    # меняет своё значение) для признака x и выбирает из них наилучшей с точки зрения\n",
    "    # минимизации меры неопределённости\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Сортирует x и y в порядке возрастания x\n",
    "        # 2. Вычисляется общее количество классов в y (в нашем случае 2 класса - 0 и 1)\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Выбираем из массива sorted_y значения в середине, кроме первых и последних min_samples_split\n",
    "        # строк (чтобы соблюсти ограничение на минимальное кол-во точек в листе дерева)\n",
    "        # 2. В np.where(...) мы находим индексы в массиве y, в которых значение y изменяется\n",
    "        # (сравнивается массив y и он же, но смещённый на одну позицию. Т.е. каждый элемент y сравнивается\n",
    "        # со следующим элементом y). Далее индекс приводится к позиции в исходной матрице.\n",
    "        # В итоге r_border_ids содержит индекс элемента в массиве sorted_y, в котором значение y изменилось\n",
    "        # по сравнению со значением в предыдущем элементе\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "        # Если для данного признака x целевой признак ни разу не изменяется, то такой признак \n",
    "        # не имеет смысла рассматривать для построения дерева\n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # 1. eq_el_count - вычисляется, как долго в массиве y сохраняется постоянное значение до очередного изменения\n",
    "        # 2,3. one_hot_code - строит массив из двух столбцов с чередующимися 0 и 1, смещёнными на одну позицию\n",
    "        # в первом и втором столбце (своеобразная \"змейка\")\n",
    "        # 4. Первый столбец one_hot_code умножается на столбец eq_el_count\n",
    "        # 5. К первой строке ещё добавляется поправка на количество разных классво в первых \n",
    "        # min_samples_split строках sorted_y\n",
    "        # В итоге в class_increments содержится таблица, в которой показано, сколько раз сохраняется каждое\n",
    "        # значение в sorted_y перед следующим изменением\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Вычисляются следующие показатели:\n",
    "        # l_class_count - количество элементво 1-го и 2-го классов в левой части разделённого массива\n",
    "        # r_class_count - количество элементов 1-го и 2-го классов в правой части разделённого массива\n",
    "        # l_sizes = размер левой половины разделённого массива\n",
    "        # r_sizes = размер правой половины разделённого массива\n",
    "        # и, т.к. разделение возможно во всех местах изменения целевого признака y, то эти показатели\n",
    "        # вычисляются для всех мест разделения\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Вычисляется мера неоднородности при разделении класса как сумма неоднородностей\n",
    "        # в левой и правой половинах\n",
    "        # 2. Индекс разделения, дающего минимальную неоднородность (лучшее разделение)\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # Что делает этот блок кода?\n",
    "        # 1. Размер левой половины разделённого массива\n",
    "        # 2. Возвращает значение меры неоднородности, а также среднее значение признака x\n",
    "        # слева и справа от границы разделения (пороговое значение)\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    \n",
    "    # Метод, который рекурсивно строит дерево решений\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        # В начале проверяем, не достигнуто ли условие окончания построения дерева\n",
    "        # (окончание рекурсивных вызовов)\n",
    "        \n",
    "        # 1. Лист ли это?\n",
    "        is_it_leaf = False\n",
    "        leaf_reason = 0  # причина, по которой мы определяем, что это лист (для отладки)\n",
    "        \n",
    "        # достигнута максимальная глубина дерева\n",
    "        if (self.max_depth is not None) and (depth >= self.max_depth):\n",
    "            is_it_leaf = True\n",
    "            leaf_reason = 1\n",
    "            \n",
    "        # достигнуто минимальное количество образцов для узла дерева    \n",
    "        if x.shape[0] <= self.min_samples_split:\n",
    "            is_it_leaf = True\n",
    "            leaf_reason = 2\n",
    "            \n",
    "        # если в узле доля одного класса больше порогового значения, \n",
    "        # то тогда не будем его дальше делить\n",
    "        main_class_shape = np.max(np.bincount(y))*1.0 / y.shape[0]\n",
    "        if main_class_shape >= self.sufficient_share:\n",
    "            is_it_leaf = True\n",
    "            leaf_reason = 3\n",
    "        \n",
    "        if is_it_leaf:  # создаём лист\n",
    "            self.tree[node_id] = self.__create_leaf_node(y, leaf_reason)\n",
    "            return\n",
    "        else:  # иначе создаём узел и разделяем его\n",
    "            # выбираем признаки для разделения (берём все столбцы из x)\n",
    "            features_ids = self.get_feature_ids(x.shape[1])  \n",
    "\n",
    "            # находим из всех признаков такой, разделение по которому обеспечивает\n",
    "            # наименьшую неопределённость (наибольший прирост информации)\n",
    "            impurity_list = []\n",
    "            threshold_list = []\n",
    "            feature_id_list = []\n",
    "            \n",
    "            for feature_id in features_ids:\n",
    "                impurity, threshold = self.__find_threshold(x[:, feature_id], y)\n",
    "                # Если threshols == None, то для данного признака x целевой признак ни разу не изменяется\n",
    "                if threshold is not None:\n",
    "                    impurity_list.append(impurity)\n",
    "                    threshold_list.append(threshold)\n",
    "                    feature_id_list.append(feature_id)\n",
    "\n",
    "            if len(impurity_list) == 0:  # тогда это лист\n",
    "                leaf_reason = 4\n",
    "                self.tree[node_id] = self.__create_leaf_node(y, leaf_reason)\n",
    "                return\n",
    "            \n",
    "            # индекс \"наилучшего\" признака, соответствующего минимальной impurity\n",
    "            min_impurity_index = impurity_list.index(min(impurity_list))\n",
    "            # id наилучшего признака\n",
    "            min_impurity_feature_id = feature_id_list[min_impurity_index]      \n",
    "            # порог для разделения\n",
    "            feature_threshold = threshold_list[min_impurity_index]\n",
    "            \n",
    "            # разделяем данные в узле\n",
    "            x_left, x_right, y_left, y_right = self.__div_samples(x, y, min_impurity_feature_id, feature_threshold)\n",
    "            \n",
    "            # если после разделения в одной из половин нет данных, то вторая половина - это лист\n",
    "            # (это одно из условий окончания рекурсии)\n",
    "            if y_left.shape[0] == 0 and y_right.shape[0] == 0:\n",
    "                return\n",
    "            if y_left.shape[0] == 0:\n",
    "                leaf_reason = 5\n",
    "                self.tree[node_id] = self.__create_leaf_node(y_right, leaf_reason)\n",
    "                return\n",
    "            if y_right.shape[0] == 0:\n",
    "                leaf_reason = 6\n",
    "                self.tree[node_id] = self.__create_leaf_node(y_left, leaf_reason)\n",
    "                return\n",
    "            # иначе создаём промежуточный узел и выполняем рекурсивный вызов для левого и правого поддеревьев\n",
    "            if y_left.shape[0] > 0 and y_right.shape[0] > 0:\n",
    "                self.tree[node_id] = self.__create_non_leaf_node(min_impurity_feature_id, feature_threshold)\n",
    "                self.__fit_node(x_left, y_left, 2 * node_id + 1, depth + 1)\n",
    "                self.__fit_node(x_right, y_right, 2 * node_id + 2, depth + 1)\n",
    "   \n",
    "\n",
    "    def __create_non_leaf_node(self, feature_id, threshold):\n",
    "        node = dict()\n",
    "        node[0] = self.__class__.NON_LEAF_TYPE\n",
    "        # feature_id \n",
    "        node[1] = feature_id\n",
    "        # threshold\n",
    "        node[2] = threshold\n",
    "        return node\n",
    "        \n",
    "    \n",
    "    def __create_leaf_node(self, y, reason):\n",
    "        node = dict()\n",
    "        node[0] = self.__class__.LEAF_TYPE\n",
    "        # назначаем листу класс - наиболее часто встречающуюся в y величину\n",
    "        node[1] = np.argmax(np.bincount(y))\n",
    "        # назначаем в листе долю основного класса\n",
    "        node[2] = np.max(np.bincount(y))*1.0 / y.shape[0]\n",
    "        # причина создания листа (для отладки)\n",
    "        node[3] = reason\n",
    "        # количество образцов в листе (нужно для слияния)\n",
    "        node[4] = y.shape[0]\n",
    "        return node\n",
    "            \n",
    "        \n",
    "    # после построения дерева сливаем листы потомки, если они дети одного\n",
    "    # родителя и имеют одинаковый класс\n",
    "    def __merge_leafs(self):\n",
    "        self.__walk_tree_and_merge_leafs(0)\n",
    "    \n",
    "    \n",
    "    def __walk_tree_and_merge_leafs(self, node_id):\n",
    "        if node_id in self.tree:       \n",
    "            node = self.tree[node_id]\n",
    "            if node[0] == self.__class__.NON_LEAF_TYPE:    \n",
    "                left_node_id = 2 * node_id + 1\n",
    "                right_node_id = 2 * node_id + 2\n",
    "                if left_node_id in self.tree and right_node_id in self.tree:\n",
    "                    left_node = self.tree[left_node_id]\n",
    "                    right_node = self.tree[right_node_id]\n",
    "                    if left_node[0] == self.__class__.LEAF_TYPE and right_node[0] == self.__class__.LEAF_TYPE:\n",
    "                        if left_node[1] == right_node[1]:\n",
    "                            # сливаем листы, оставляя узел с меньшим id\n",
    "                            # основной класс\n",
    "                            main_class = left_node[1]\n",
    "                            # кол-во образцов в левом и правом узлах\n",
    "                            y_size_left = left_node[4]\n",
    "                            y_size_right = right_node[4]\n",
    "                            # доля основного класса в левом и правом узлах\n",
    "                            p_left = left_node[2]\n",
    "                            p_right = right_node[2]\n",
    "                            # количество образцов основного класса в левом и правом узлах\n",
    "                            y_max_left = p_left * y_size_left\n",
    "                            y_max_right = p_right * y_size_right\n",
    "                            \n",
    "                            y_max_merge = y_max_left + y_max_right\n",
    "                            y_size_merge = y_size_left + y_size_right\n",
    "                            p_merge = y_max_merge / y_size_merge\n",
    "                            \n",
    "                            node_merge = dict()\n",
    "                            node_merge[0] = self.__class__.LEAF_TYPE\n",
    "                            node_merge[1] = main_class\n",
    "                            node_merge[2] = p_merge\n",
    "                            node_merge[3] = 7\n",
    "                            node_merge[4] = y_size_merge\n",
    "                            \n",
    "                            self.tree[left_node_id] = node_merge\n",
    "                            self.tree.pop(right_node_id)\n",
    "                    else:\n",
    "                        if left_node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "                            self.__walk_tree_and_merge_leafs(left_node_id)\n",
    "                        if right_node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "                            self.__walk_tree_and_merge_leafs(right_node_id)\n",
    "    \n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size  # количество классов признаков. В нашем случае 2 класса - 0 или 1\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "        # self.__merge_leafs()\n",
    "\n",
    "        \n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "        \n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    \n",
    "    def printtree(self, indent=''):\n",
    "        self.__print_node(0, '')\n",
    "    \n",
    "    \n",
    "    def __print_node(self, node_id, indent):\n",
    "        if node_id in self.tree:\n",
    "            indent += ' '\n",
    "            \n",
    "            node = self.tree[node_id]\n",
    "            if node[0] == self.__class__.NON_LEAF_TYPE:    \n",
    "                print('{} {}: feature_id={}, threshold={}'.format(indent, node_id, node[1], node[2]))\n",
    "                self.__print_node(2 * node_id + 1, indent)\n",
    "                self.__print_node(2 * node_id + 2, indent)\n",
    "            if node[0] == self.__class__.LEAF_TYPE:\n",
    "                print('{} {}: reason={}, class={}, p={}'.format(indent, node_id, node[3], node[1], node[2]))\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "1                 2.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "5                 0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])  # столбцы, кроме первого - определяющие признаки\n",
    "y = df.as_matrix(columns=df.columns[:1])  # первый столбец (SeriousDlqin2yrs) - целевой признак\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=None)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483305931091\n",
      "0.962697982788\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.070009146088\n",
      "0.930614450819\n",
      "0.932152656523\n",
      "0.930365012056\n",
      "0.0705941046855\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred=my_clf.predict(X_test)\n",
    "    y_true=y_test\n",
    "    acc_score = accuracy_score(y_pred, y_true)\n",
    "    \n",
    "    print(acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, не получилось найти ошибку. Явно виден какой-то \"перескок\" при определении класса. Т.е. в каких-то случаях классы предсказываются с точностью до наоборот. У меня ощущение, что это может быть связано с какой-то ошибкой округления при определнии порога, но непонятно..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892949197639\n",
      "0.890870541282\n",
      "0.892907624512\n",
      "0.89452897647\n",
      "0.893235771006\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "df_test = pd.read_csv('test.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Sex   Age  SibSp  Parch     Fare  Survived\n",
       "PassengerId                                                       \n",
       "2                 1  female  38.0      1      0  71.2833         1\n",
       "4                 1  female  35.0      1      0  53.1000         1\n",
       "7                 1    male  54.0      0      0  51.8625         0\n",
       "11                3  female   4.0      1      1  16.7000         1\n",
       "12                1  female  58.0      0      0  26.5500         1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\n",
    "df_test = df_test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex'] = df_train['Sex'].map({'male': 0, 'female': 1})\n",
    "df_test['Sex'] = df_test['Sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Survived', axis=1).as_matrix()\n",
    "y_train = df_train['Survived'].as_matrix()\n",
    "\n",
    "X_test = df_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDecisionTreeClassifier(min_samples_split=2, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672131147541\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "print(accuracy_score(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: feature_id=1, threshold=0.5\n",
      "   1: feature_id=5, threshold=10.5\n",
      "    3: reason=5, class=1, p=0.963414634146\n",
      "    4: feature_id=4, threshold=0.0\n",
      "     9: reason=3, class=0, p=1.0\n",
      "     10: reason=4, class=1, p=0.75\n",
      "   2: feature_id=2, threshold=17.5\n",
      "    5: reason=5, class=0, p=0.620689655172\n",
      "    6: reason=3, class=1, p=1.0\n"
     ]
    }
   ],
   "source": [
    "model.printtree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево получилось неглубокое. Видим, что оно делится по полу (feature_id = 1), и дальше по возрасту и стоимости билета. Точность предсказания не слишком высокая, наверное потому, что учитывается мало признаков."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
